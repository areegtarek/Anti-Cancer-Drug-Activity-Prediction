{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vsxoMjV8jMPn",
        "YrTzZuGsjq0P",
        "chtYPbAlPiod",
        "Q81ZSVvXhMSB",
        "IBA7VX6xhMSV",
        "t_TggR4AhMSa",
        "ZReqwjj2Kkjl",
        "MR8hAIU9LMat",
        "YuxvsHDZwEAh",
        "3nV06VQMJjdT",
        "Ka-p6mJPJDga",
        "FJe1eiOOLXmG",
        "eASbS5s1QwAK",
        "2m8IPAB1wZAd",
        "YqtrUyrhRKt7",
        "Xq-gX-L8RcVz",
        "A9juJqkkVWI2",
        "Eg_5KuzzVcEZ",
        "vFSga8h1wse3",
        "FiDOZaDDVcEc",
        "RlXzOswhVcEg",
        "4IXmzRV8Xi9e",
        "adXgzA50Xi9f",
        "-7ojWP5Gw08u",
        "m26_DpZQXi9j",
        "SFEGcLTNXi9q",
        "1HiZqdoHYvj4",
        "Cc45PxcXYvj9",
        "6WMuTu-GYvj_",
        "aFvb6qK065Xp",
        "5i6mQwABZf9J",
        "W4qhgL6QxGe-",
        "6QQMjtZzZf9L",
        "1QdUTEbZZf9N",
        "IdxF4TOKa6WY",
        "oMpGhSnwa6WZ",
        "AWiq6Ei-xP6u",
        "Em2pqeWxa6Wc",
        "YD-PyevTa6We",
        "EoMtjEyS5L7C",
        "R7vVAyKw5L7C",
        "snxwaG385L7E",
        "Qb7iN2Wr5L7F",
        "-QjL1LIw5L7G",
        "D2LUjuJHKDUO",
        "97QQYduCKDUP",
        "RI819obPLKDS",
        "GvQ0Il0wLKDU"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf3d5bfa0585435089373f609cfd1c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bcb7b5f4adc4cdd8624c94c9bb56419",
              "IPY_MODEL_f466c526b2354188b2f9db60263473b8",
              "IPY_MODEL_9a2a2a2092374556aedcf07b37841dbe"
            ],
            "layout": "IPY_MODEL_7d99c0a7f4aa4ff2a5b56d858f5fa325"
          }
        },
        "4bcb7b5f4adc4cdd8624c94c9bb56419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5a0aeac6c8549d18332c57d2c1f8a3f",
            "placeholder": "​",
            "style": "IPY_MODEL_4d317fcbdcac43eba20cbec3d969ecfa",
            "value": "100%"
          }
        },
        "f466c526b2354188b2f9db60263473b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf98a20685bd463aace50b61282239bd",
            "max": 25024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75c5570fa3d249b1bc31e2e3bbf69ab9",
            "value": 25024
          }
        },
        "9a2a2a2092374556aedcf07b37841dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63acf47aaae6468b9af7a2fef64247c9",
            "placeholder": "​",
            "style": "IPY_MODEL_063bc673d45a40b88414cfed24e3bf2b",
            "value": " 25024/25024 [00:01&lt;00:00, 16386.97it/s]"
          }
        },
        "7d99c0a7f4aa4ff2a5b56d858f5fa325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5a0aeac6c8549d18332c57d2c1f8a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d317fcbdcac43eba20cbec3d969ecfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf98a20685bd463aace50b61282239bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c5570fa3d249b1bc31e2e3bbf69ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63acf47aaae6468b9af7a2fef64247c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "063bc673d45a40b88414cfed24e3bf2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "584d418e5ad54926b94e77caaf612816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_934bd8154b264bc588df5bf83ac82cc9",
              "IPY_MODEL_2bf2eb1b90a64b90afd48eedb5017aff",
              "IPY_MODEL_ad1878cce95b46d58d8201dcf04aa3f7"
            ],
            "layout": "IPY_MODEL_b38d052cffd04dc1943d4d71ba026b62"
          }
        },
        "934bd8154b264bc588df5bf83ac82cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7849dadabc248758587274fe3c3dd67",
            "placeholder": "​",
            "style": "IPY_MODEL_1f109645c6564c76b58db66faf3ee6fb",
            "value": "100%"
          }
        },
        "2bf2eb1b90a64b90afd48eedb5017aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_027348596afc4e64bc74cc4f5a3b8a42",
            "max": 12326,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1615950593eb4163b282e91b0847145b",
            "value": 12326
          }
        },
        "ad1878cce95b46d58d8201dcf04aa3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adbd7ee50f0b4f579236dc96b4e72c36",
            "placeholder": "​",
            "style": "IPY_MODEL_18ac31aa970a4a6bb3161f202d3ce9d1",
            "value": " 12326/12326 [00:01&lt;00:00, 10668.40it/s]"
          }
        },
        "b38d052cffd04dc1943d4d71ba026b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7849dadabc248758587274fe3c3dd67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f109645c6564c76b58db66faf3ee6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "027348596afc4e64bc74cc4f5a3b8a42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1615950593eb4163b282e91b0847145b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adbd7ee50f0b4f579236dc96b4e72c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ac31aa970a4a6bb3161f202d3ce9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/areegtarek/Anti-Cancer-Drug-Activity-Prediction/blob/main/Anti_Cancer_Drug_Activity_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Problem definition And questions Solutions** "
      ],
      "metadata": {
        "id": "vsxoMjV8jMPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "😊 Problem Definition: \n",
        "  * It is a binary classification problem based on the graph data. \n",
        "  * The task is to predict the anticancer activity of a chemical compound using the chemical structure of the compound. \n",
        "  *The chemical compound can be positive or negative against lung cancer cell and thus labelled as either 0 or 1."
      ],
      "metadata": {
        "id": "90iAZfljZMVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "😊 Define the data input and output:-\n",
        "* The data is in the form of graph which represents the chemical structure of the compound. \n",
        "* Each sample of data contains information about the atoms and the connections between atoms of the molecule. \n",
        "* So in this problem the features are the atoms and connections.\n",
        "* The input file is structure data file (SDF). It contains information about the chemical composition of a molecule. SDF file store information about position of individual atom in the chemical compound and also tells about the connections."
      ],
      "metadata": {
        "id": "lCgZFc6aa1kZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "😊 What is the experimental protocol used and how was it carried out?\n",
        "* The first step is to read the sdf file to get the information about the atoms and their connectivity in the compound. The atoms are described as nodes and connections are described as edges. The read_sdf method is used to read sdf file and the chemical composition of the compound.\n",
        "* The nodes are given as characters (like [O,N,...]). Thus it is treated as sequence of text data and best way to describe the text data sequence to tokenize the data and then adding the embeddig layer.\n",
        "* Graph convolutional network is used to calculate the probability of the output class. Different methods differ in implementing message passing methods. "
      ],
      "metadata": {
        "id": "RHfoXltvfWrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✔️ **Answer the questions :**\n",
        "---\n",
        "---\n",
        "🌈**Based on the provided template, describe the format of the input file (sdf file).**\n",
        "\n",
        "* The input file is structure data file (SDF). It contains information about the chemical composition of a molecule. SDF file store information about position of individual atom in the chemical compound and also tells about the connections. Different molecules are delimited by```$$$$```expression.\n",
        "---\n",
        "* Each sample/molecule starts with header which tells about the name/title of the compound. Other sections includes information about Atom count, version number, connections etc. Atom block tells about the elements of the compound. Bond block block tells about the bonding structure of the compound. These both blocks are used in this assignment to get information about the compound and saving them in form of edges and nodes. Each node is the atom given in the chemical molecule.\n",
        "---\n",
        "---\n",
        "🌈**What are the input tensors to the neural network model (their meaning, not just symbol)? What is each of their dims and their meaning (e.g. batch_size)?**\n",
        "\n",
        "The input tensors in this network are:\n",
        "\n",
        "* data: The data contains the nodes of the chemical compound in the tokenized form. Nodes for each compound are extracted, then they are tokenized using the tokenizer and finally padding is done using pad_sequence method. The shape for each batch is [batch_size*max_len_nodes], where batch_size is the number of samples in the batch and max_len_nodes is the length of tokenized nodes after padding is done.\n",
        "---\n",
        "* edge: edge is the input tensor which carries information about connections between atoms. The shape of edge is [sum_of_all_edges,2]. The sum_of_all_edges represents the sum(no. of edges of each sample) of the batch_size. For example in a batch of 3 samples, the number of edges in sample 1: 21, sample 2: 20 and sample 3: 40. So the size of edge tensor would be [81,2].\n",
        "---\n",
        "* node2graph: It is the input tensor which is used for segmented mean and contains information about segmented ids. The shape for each batch is [batch_size*max_len_nodes], where batch_size is the number of samples in the batch and max_len_nodes is the length of tokenized nodes after padding is done.\n",
        "---\n",
        "---\n",
        "🌈**For each dim of gnn_out, what does it symbolize? For each dim of avg, what does it symbolize?**\n",
        "\n",
        "* gnn_out: The gnn_out is of shape [batch_size_node_dimension,hidden layers], where batch_size_node_dimension is the dimension of the input data (node) vector (dimension of tokenized vector for the complete batch). It represents the aggregation output of the model for each hidden layer.\n",
        "---\n",
        "*  avg: Average takes the segmented mean of the gnn_out based on the segmented ids. For each sample in the batch_size, the output of gnn_out is [tokenized_vector_dimension, hidden_layers]. Each sample has one segment id. Thus the segment_mean takes the mean of all the output data in the gnn_out output and represents one sample with one number for each hidden layer. The final output of the avg tensor is of shape [batch_size, hidden_layer]. It is a way of collecting information for each sample and representing it in the form of mean data.\n",
        "---\n",
        "---\n",
        "🌈**What is the difference between segment_mean and tf.reduce_mean? For each dim of pred, what does it symbolize?**\n",
        "\n",
        "* segment_mean takes the mean of the data which have same segmented ids.\n",
        "---\n",
        "* reduce_mean: computes the mean of elements across dimensions of a tensor given the arguments.\n",
        " Use TensorFlow reduce_mean operation to calculate the mean of tensor elements along various dimensions of the tensor.\n",
        "\n",
        "---\n",
        "* pred: The final output (pred) tells about the probability of a chemical compound to be active for the cancer cell or not. The shape of pred is [batch_size,1]. Thus for each sample, the final output is a number which represents the probability associated with each chemical compound about its activity.\n",
        "---\n",
        "---\n",
        "🌈**What is the motivation/theory/idea to use multiple gcn layers comparing to just one? How many layers were used in the template?**\n",
        "\n",
        "* The default template implements the default setting of the number of layers in the gcn network. \n",
        "* The default layer are 4 as given in the documentaion. \n",
        "* The default message passing method is rgcn (Graph convolution layers). \n",
        "* Using multiple gcn helps in incorporating all the graph complexity properly and thus creates a better model."
      ],
      "metadata": {
        "id": "YrTzZuGsjq0P"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chtYPbAlPiod"
      },
      "source": [
        "#Download The data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI1xc6dK1ucS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "2df24dc1-4c6b-4876-8b62-af7a8f128b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.0.12)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d78f5286-17de-40e7-a8ec-3d92e24717ab\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d78f5286-17de-40e7-a8ec-3d92e24717ab\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 66 bytes\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "#Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCZsGPsKPm5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af59ab28-238b-4aa1-ea35-d62a44f1b821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CISC873-DM-W23-A6.zip to /content\n",
            "\r  0% 0.00/3.86M [00:00<?, ?B/s]\n",
            "\r100% 3.86M/3.86M [00:00<00:00, 217MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c CISC873-DM-W23-A6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fGxNeN0PodL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62799f63-9e75-4b8d-f7f0-f00063139426"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  CISC873-DM-W23-A6.zip\n",
            "  inflating: gcnn-template.ipynb     \n",
            "  inflating: test_x.sdf              \n",
            "  inflating: train.sdf               \n"
          ]
        }
      ],
      "source": [
        "! unzip CISC873-DM-W23-A6.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q81ZSVvXhMSB"
      },
      "source": [
        "# **Read SDF format data (structured-data format)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm_v7m8ahMSN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def read_sdf(file): \n",
        "#opening the file in read mode >>> 'r'            \n",
        "    with open(file, 'r') as rf:     \n",
        "#reading the contents of the file\n",
        "        content = rf.read()        \n",
        "#splitting the read file by delimiter $$$$  in the file thus splitting each molecule in an array        \n",
        "    samples = content.split('$$$$')\n",
        "#method to read each molecule configuration\n",
        "#s  represents one molecule\n",
        "    def parse_sample(s):\n",
        "#splitting the text data to lines\n",
        "        lines = s.splitlines()\n",
        "#empty array for links to save the values of links \n",
        "        links = []\n",
        "#empty array to save the nodes \n",
        "        nodes = []\n",
        "        label = 0\n",
        "#for loop over each line\n",
        "        for l in lines:\n",
        "            if l.strip() == '1.0':\n",
        "                label = 1\n",
        "            if l.strip() == '-1.0':\n",
        "                label = 0\n",
        "#for Atom block \n",
        "            if l.startswith('    '):\n",
        "#splitting line\n",
        "                feature = l.split()\n",
        "#node feature (atom) as O,C , \n",
        "                node = feature[3]\n",
        "#appending nodes\n",
        "                nodes.append(node)\n",
        "#bond block tells about connections between atoms\n",
        "            elif l.startswith(' '):\n",
        "#splitting line\n",
        "                lnk = l.split()\n",
        "# edge: (from, to,) (1-based index)\n",
        "                if int(lnk[0]) - 1 < len(nodes):\n",
        "#appending links\n",
        "                    links.append((\n",
        "#first atom\n",
        "                        int(lnk[0])-1, \n",
        "# zero-based index #second atom\n",
        "                        int(lnk[1])-1, # zero-based index\n",
        "# int(lnk[2]) ignore edge weight\n",
        "                    ))\n",
        "#returning nodes, links and label                    \n",
        "        return nodes, np.array(links), label\n",
        "#parse_sample for each molecule    \n",
        "    return [parse_sample(s) for s in tqdm(samples) if len(s[0]) > 0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read raw train data\n",
        "!unzip /content/train_test.zip\n",
        "#load  train.sdf file\n",
        "training_set = read_sdf('train.sdf')\n",
        "#load test_x.sdf file\n",
        "testing_set  = read_sdf('test_x.sdf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "bf3d5bfa0585435089373f609cfd1c9c",
            "4bcb7b5f4adc4cdd8624c94c9bb56419",
            "f466c526b2354188b2f9db60263473b8",
            "9a2a2a2092374556aedcf07b37841dbe",
            "7d99c0a7f4aa4ff2a5b56d858f5fa325",
            "a5a0aeac6c8549d18332c57d2c1f8a3f",
            "4d317fcbdcac43eba20cbec3d969ecfa",
            "bf98a20685bd463aace50b61282239bd",
            "75c5570fa3d249b1bc31e2e3bbf69ab9",
            "63acf47aaae6468b9af7a2fef64247c9",
            "063bc673d45a40b88414cfed24e3bf2b",
            "584d418e5ad54926b94e77caaf612816",
            "934bd8154b264bc588df5bf83ac82cc9",
            "2bf2eb1b90a64b90afd48eedb5017aff",
            "ad1878cce95b46d58d8201dcf04aa3f7",
            "b38d052cffd04dc1943d4d71ba026b62",
            "b7849dadabc248758587274fe3c3dd67",
            "1f109645c6564c76b58db66faf3ee6fb",
            "027348596afc4e64bc74cc4f5a3b8a42",
            "1615950593eb4163b282e91b0847145b",
            "adbd7ee50f0b4f579236dc96b4e72c36",
            "18ac31aa970a4a6bb3161f202d3ce9d1"
          ]
        },
        "id": "PemubsfMyhv7",
        "outputId": "c405f7ab-46b4-460b-c431-97138c93fef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/train_test.zip, /content/train_test.zip.zip or /content/train_test.zip.ZIP.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf3d5bfa0585435089373f609cfd1c9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12326 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "584d418e5ad54926b94e77caaf612816"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrynV47phMSQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#splitting the train data into training set and validation set by 85 to 15 \n",
        "training_set, validation_set = train_test_split(training_set, test_size=0.15,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1s1ibivhMSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e839b0-e9fd-40d9-893d-ecc7838de8a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['Br', 'Cl', 'O', 'N', 'N', 'N', 'N', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C', 'C'], array([[ 0, 21],\n",
            "       [ 1, 10],\n",
            "       [ 2, 25],\n",
            "       [ 2, 28],\n",
            "       [ 3, 10],\n",
            "       [ 3, 15],\n",
            "       [ 4, 12],\n",
            "       [ 4, 16],\n",
            "       [ 5, 16],\n",
            "       [ 6, 19],\n",
            "       [ 7,  8],\n",
            "       [ 7,  9],\n",
            "       [ 7, 13],\n",
            "       [ 8, 10],\n",
            "       [ 8, 14],\n",
            "       [ 9, 16],\n",
            "       [ 9, 19],\n",
            "       [11, 14],\n",
            "       [11, 15],\n",
            "       [11, 18],\n",
            "       [12, 13],\n",
            "       [12, 17],\n",
            "       [15, 20],\n",
            "       [17, 23],\n",
            "       [17, 24],\n",
            "       [18, 21],\n",
            "       [20, 22],\n",
            "       [21, 22],\n",
            "       [23, 26],\n",
            "       [24, 27],\n",
            "       [25, 26],\n",
            "       [25, 27]]), 0)\n"
          ]
        }
      ],
      "source": [
        "#print index 1 in the training set\n",
        "print(training_set[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBA7VX6xhMSV"
      },
      "source": [
        "# **Visualizing/Inspecting a Sample**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training set contains data for each sample(molecule). Each sample array contains three elements. First element has information about the atoms in text format, second element has information about the connections and third element tells about the label for each molecule."
      ],
      "metadata": {
        "id": "OeT6NfXHKybz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK1fWnZ0hMSW"
      },
      "outputs": [],
      "source": [
        "#importing libraries for displaying network of molecule\n",
        "!pip install --quiet networkx\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "colors = cm.rainbow(np.linspace(0, 1, 50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm9dG-_qhMSX"
      },
      "outputs": [],
      "source": [
        "#method to visualize the compound graph\n",
        "#atoms are given as nodes\n",
        "#the connections are defined as edges\n",
        "def visualize(sample):\n",
        "#initiating an instance of Graph\n",
        "    G=nx.Graph() \n",
        "#atoms as nodes\n",
        "    nodes = sample[0] \n",
        "#connections as edges\n",
        "    edges = sample[1] \n",
        "#empty dictionary for labels for the nodes\n",
        "    labeldict={} \n",
        "#empty array for each node color\n",
        "    node_color=[] \n",
        "#for each node in the sample\n",
        "    for i,n in enumerate(nodes): \n",
        "#adding node to the graph each node as (0,1,2,3..)\n",
        "        G.add_node(i)   \n",
        "#dictionary building with [key,value] as [0:'C']\n",
        "        labeldict[i]=n  \n",
        "#print(i)\n",
        "#print(n)\n",
        "#color coding\n",
        "        node_color.append(colors[hash(n)%len(colors)]) \n",
        "\n",
        "# a list of nodes:\n",
        "#for each edge\n",
        "    for e in edges:\n",
        "#adding egde to the graph from one connection to other connection\n",
        "        G.add_edge(e[0], e[1]) \n",
        "#drawing the graph with labels for nodes as atoms and connections as edges    \n",
        "    nx.draw(G, labels=labeldict, with_labels = True, node_color = node_color)\n",
        "    plt.show()\n",
        "#returns graph\n",
        "    return G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu04nA2FhMSZ",
        "outputId": "961bd3b4-ff8e-4b3e-8649-32c0edf89a3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x7f5e1ca52f10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#displaying one sample\n",
        "plt.clf()\n",
        "visualize(training_set[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_TggR4AhMSa"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxLlarighMSb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "max_vocab = 500\n",
        "max_len = 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "all_nodes = [s[0] for s in training_set]\n",
        "tokenizer = Tokenizer(num_words=max_vocab)\n",
        "tokenizer.fit_on_texts(all_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mizZeMIIhMSb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import random\n",
        "random.seed(10)\n",
        "\n",
        "#method to prepare single batch set\n",
        "#samples represents the batch of data\n",
        "def prepare_single_batch(samples):\n",
        " #nodes characters array\n",
        "    sample_nodes = [s[0] for s in samples]  \n",
        "#tokenizing the sample nodes                   \n",
        "    sample_nodes = tokenizer.texts_to_sequences(sample_nodes)   \n",
        "#pad_sequences for each sample node with post padding\n",
        "    sample_nodes = pad_sequences(sample_nodes, padding='post')  \n",
        "#maximum length of nodes \n",
        "    max_nodes_len = np.shape(sample_nodes)[1]                   \n",
        "#defining edges\n",
        "    edges = [s[1]+i*max_nodes_len for i,s in enumerate(samples)] \n",
        "    edges = [e for e in edges if len(e) > 0]\n",
        "#array definition for segmented_ids\n",
        "    node_to_graph = [[i]*max_nodes_len for i in range(len(samples))]  \n",
        "#reshaping as 1 vector\n",
        "    all_nodes = np.reshape(sample_nodes, -1)  \n",
        "#concatenating all the edges as size [total_edges ,2]\n",
        "    all_edges = np.concatenate(edges)         \n",
        "\n",
        "    node_to_graph = np.reshape(node_to_graph, -1)\n",
        "#returns a dictionary of features(data,edges,node2grah) and label\n",
        "    return {\n",
        "        'data': all_nodes,\n",
        "        'edges': all_edges,\n",
        "        'node2grah': node_to_graph,\n",
        "    }, np.array([s[2] for s in samples]) \n",
        "\n",
        "#generating batch with given btch_size\n",
        "def gen_batch(dataset, batch_size=16, repeat=False, shuffle=True):\n",
        " #infinity loop\n",
        "    while True:                \n",
        "#data in the array\n",
        "        dataset = list(dataset) \n",
        "# if shuffle is True\n",
        "        if shuffle:             \n",
        "#randomly shuffling\n",
        "            random.shuffle(dataset) \n",
        "#length of dataset\n",
        "        l = len(dataset)  \n",
        "#loop for  creating batches from given dataset\n",
        "        for ndx in range(0, l, batch_size):  \n",
        "#creating batch samples with given batch_size\n",
        "            batch_samples = dataset[ndx:min(ndx + batch_size, l)] \n",
        "#returning a generator with prepared batches\n",
        "            yield prepare_single_batch(batch_samples)  \n",
        "#breaking loop if repeat is false \n",
        "        if not repeat:  \n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ahKQi_8hMSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078e813c-31f0-4580-ea51-20e2298a18e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\n",
            "[ 5  4  2  3  3  3  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "  1  1  0  0  0  0  0  0  0  4  2  2  2  3  3  1  1  1  1  1  1  1  1  1\n",
            "  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  5  5  2  2  2  3\n",
            "  3  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
            "  1  1  1 10  7  2  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "edges\n",
            "[[  0  22]\n",
            " [  1   8]\n",
            " [  2  10]\n",
            " [  2  11]\n",
            " [  3   5]\n",
            " [  3   7]\n",
            " [  3   8]\n",
            " [  4   6]\n",
            " [  4   7]\n",
            " [  5  13]\n",
            " [  6   8]\n",
            " [  7   9]\n",
            " [  9  16]\n",
            " [  9  17]\n",
            " [ 10  12]\n",
            " [ 10  14]\n",
            " [ 11  13]\n",
            " [ 11  15]\n",
            " [ 12  18]\n",
            " [ 12  19]\n",
            " [ 14  15]\n",
            " [ 16  20]\n",
            " [ 17  21]\n",
            " [ 18  23]\n",
            " [ 19  24]\n",
            " [ 20  25]\n",
            " [ 21  25]\n",
            " [ 22  23]\n",
            " [ 22  24]\n",
            " [ 33  40]\n",
            " [ 33  41]\n",
            " [ 34  48]\n",
            " [ 35  56]\n",
            " [ 35  57]\n",
            " [ 36  56]\n",
            " [ 37  39]\n",
            " [ 37  48]\n",
            " [ 38  55]\n",
            " [ 38  56]\n",
            " [ 39  40]\n",
            " [ 39  44]\n",
            " [ 39  45]\n",
            " [ 40  43]\n",
            " [ 41  42]\n",
            " [ 41  46]\n",
            " [ 42  43]\n",
            " [ 42  47]\n",
            " [ 44  49]\n",
            " [ 45  50]\n",
            " [ 46  52]\n",
            " [ 47  53]\n",
            " [ 48  54]\n",
            " [ 49  51]\n",
            " [ 50  51]\n",
            " [ 52  53]\n",
            " [ 54  55]\n",
            " [ 57  58]\n",
            " [ 57  59]\n",
            " [ 57  60]\n",
            " [ 66  90]\n",
            " [ 67  96]\n",
            " [ 68  75]\n",
            " [ 69  88]\n",
            " [ 70  92]\n",
            " [ 71  75]\n",
            " [ 71  85]\n",
            " [ 72  73]\n",
            " [ 72  88]\n",
            " [ 73  92]\n",
            " [ 74  75]\n",
            " [ 74  76]\n",
            " [ 74  77]\n",
            " [ 74  78]\n",
            " [ 76  79]\n",
            " [ 77  80]\n",
            " [ 78  81]\n",
            " [ 79  83]\n",
            " [ 79  84]\n",
            " [ 80  82]\n",
            " [ 80  84]\n",
            " [ 81  82]\n",
            " [ 81  83]\n",
            " [ 85  86]\n",
            " [ 85  87]\n",
            " [ 86  88]\n",
            " [ 86  89]\n",
            " [ 87  90]\n",
            " [ 89  91]\n",
            " [ 90  91]\n",
            " [ 92  93]\n",
            " [ 93  94]\n",
            " [ 93  95]\n",
            " [ 94  97]\n",
            " [ 95  98]\n",
            " [ 96  97]\n",
            " [ 96  98]\n",
            " [ 99 104]\n",
            " [100 104]\n",
            " [101 105]\n",
            " [102 103]\n",
            " [102 104]\n",
            " [102 105]\n",
            " [103 106]\n",
            " [103 107]\n",
            " [106 108]\n",
            " [107 109]\n",
            " [108 110]\n",
            " [109 110]]\n",
            "node2grah\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
            "label [0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# showing one batch:\n",
        "for train_batch in gen_batch(training_set, batch_size=4):\n",
        "    for k,v in train_batch[0].items():\n",
        "        print(k)\n",
        "        print(v)\n",
        "        pass\n",
        "    print('label', train_batch[1])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8MqrfhVhMSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5825e796-8d0c-40f0-989d-624dec22987b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.5/135.5 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.9/173.9 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for tf2_gnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet tf2_gnn\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#for deep Graph Neural Network\n",
        "from tf2_gnn.layers.gnn import GNN, GNNInput"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 1**"
      ],
      "metadata": {
        "id": "ZReqwjj2Kkjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i didn't change in the template so the accurracy between 70 and 78 % so  i will change in the hyperparameaters in the next trials and recheck the performance "
      ],
      "metadata": {
        "id": "nQblYnnZhui6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "MR8hAIU9LMat"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1WyfDCkhMSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df0cc489-b597-4512-f025-a0ac49bbf2eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='gnn/StatefulPartitionedCall:0', description=\"created by layer 'gnn'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='tf.math.segment_mean/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense/Sigmoid:0', description=\"created by layer 'dense'\")\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLambda  ()                  0           ['input_3[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 100)          50000       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  ()                  0           ['tf.math.reduce_max[0][0]']     \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " gnn (GNN)                      (None, 40)           35440       ['embedding[0][0]',              \n",
            "                                                                  'input_2[0][0]',                \n",
            "                                                                  'input_3[0][0]',                \n",
            "                                                                  'tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.math.segment_mean (TFOpLamb  (None, 40)          0           ['gnn[0][0]',                    \n",
            " da)                                                              'input_3[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            41          ['tf.math.segment_mean[0][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 85,481\n",
            "Trainable params: 85,481\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#importing tensorflow and other libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean #to calculate segmented mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model #layers and model\n",
        "from tensorflow.keras.layers import Embedding, Dense #layers\n",
        "from tensorflow.keras.optimizers import Adam #optimizer\n",
        "\n",
        "\n",
        "#Input layer for nodes (tokenized text data) \n",
        "data = keras.Input(batch_shape=(None,))             \n",
        "\n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data         \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)  \n",
        "#Input layer for node2graph ids    \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n",
        "#embedding layer over data with each token embedded as  size vector \n",
        "embeded = Embedding(tokenizer.num_words, 100)(data)  \n",
        "\n",
        "# number of graphs (number of samples)\n",
        "#calculating number of samples (or min(batch_size,no._of_samples))    \n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "\n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer\n",
        "#sets the size of the output of all message passing layers.\n",
        "params[\"hidden_dim\"] = 40  \n",
        "\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "#outpur shape: [data_dimension,hidden layers]   \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    ) #shape: [batch_size,64]  \n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid\n",
        " #output shape: [batch_size,1]\n",
        "pred = Dense(1, activation='sigmoid')(avg)  \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "#inputs are data,edges and node2graph\n",
        "#input: dictionary\n",
        "#output: prediction value from dense layer\n",
        "model = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#printing summary of the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "YuxvsHDZwEAh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4PiB_rphMSf"
      },
      "outputs": [],
      "source": [
        "#compile the model by usnig adam as optimizer and \n",
        "#using binarycrossentropy for calculate the loss and check the acc by AUC \n",
        "model.compile( optimizer='adam',\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "3nV06VQMJjdT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0TX4ya6hMSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b496ad-f557-49cd-9254-ac2f7740ca26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "2659/2659 [==============================] - 62s 19ms/step - loss: 0.2085 - auc: 0.5638 - val_loss: 0.1923 - val_auc: 0.6317\n",
            "Epoch 2/26\n",
            "2659/2659 [==============================] - 35s 13ms/step - loss: 0.1871 - auc: 0.6610 - val_loss: 0.1874 - val_auc: 0.6797\n",
            "Epoch 3/26\n",
            "2659/2659 [==============================] - 33s 13ms/step - loss: 0.1836 - auc: 0.6895 - val_loss: 0.1791 - val_auc: 0.7270\n",
            "Epoch 4/26\n",
            "2659/2659 [==============================] - 35s 13ms/step - loss: 0.1789 - auc: 0.7155 - val_loss: 0.1787 - val_auc: 0.7272\n",
            "Epoch 5/26\n",
            "2659/2659 [==============================] - 36s 14ms/step - loss: 0.1758 - auc: 0.7375 - val_loss: 0.1727 - val_auc: 0.7586\n",
            "Epoch 6/26\n",
            "2659/2659 [==============================] - 39s 15ms/step - loss: 0.1741 - auc: 0.7506 - val_loss: 0.1713 - val_auc: 0.7659\n",
            "Epoch 7/26\n",
            "2659/2659 [==============================] - 35s 13ms/step - loss: 0.1752 - auc: 0.7428 - val_loss: 0.1689 - val_auc: 0.7650\n",
            "Epoch 8/26\n",
            "2659/2659 [==============================] - 32s 12ms/step - loss: 0.1700 - auc: 0.7729 - val_loss: 0.1730 - val_auc: 0.7600\n",
            "Epoch 9/26\n",
            "2659/2659 [==============================] - 34s 13ms/step - loss: 0.1704 - auc: 0.7646 - val_loss: 0.1693 - val_auc: 0.7758\n",
            "Epoch 10/26\n",
            "2659/2659 [==============================] - 34s 13ms/step - loss: 0.1707 - auc: 0.7652 - val_loss: 0.1638 - val_auc: 0.7882\n",
            "Epoch 11/26\n",
            "2659/2659 [==============================] - 34s 13ms/step - loss: 0.1682 - auc: 0.7738 - val_loss: 0.1711 - val_auc: 0.7619\n",
            "Epoch 12/26\n",
            "2659/2659 [==============================] - 35s 13ms/step - loss: 0.1669 - auc: 0.7767 - val_loss: 0.1676 - val_auc: 0.7954\n",
            "Epoch 13/26\n",
            "2659/2659 [==============================] - 34s 13ms/step - loss: 0.1675 - auc: 0.7761 - val_loss: 0.1705 - val_auc: 0.7758\n",
            "Epoch 14/26\n",
            "2659/2659 [==============================] - 36s 13ms/step - loss: 0.1674 - auc: 0.7780 - val_loss: 0.1659 - val_auc: 0.7930\n",
            "Epoch 15/26\n",
            "2659/2659 [==============================] - 34s 13ms/step - loss: 0.1670 - auc: 0.7793 - val_loss: 0.1678 - val_auc: 0.7931\n",
            "Epoch 16/26\n",
            "2659/2659 [==============================] - 34s 13ms/step - loss: 0.1636 - auc: 0.7957 - val_loss: 0.1659 - val_auc: 0.7895\n",
            "Epoch 17/26\n",
            "2659/2659 [==============================] - 34s 13ms/step - loss: 0.1651 - auc: 0.7892 - val_loss: 0.1657 - val_auc: 0.7800\n",
            "Epoch 18/26\n",
            "2659/2659 [==============================] - 34s 13ms/step - loss: 0.1622 - auc: 0.7961 - val_loss: 0.1654 - val_auc: 0.7910\n",
            "Epoch 19/26\n",
            "2659/2659 [==============================] - 35s 13ms/step - loss: 0.1639 - auc: 0.7905 - val_loss: 0.1681 - val_auc: 0.7791\n",
            "Epoch 20/26\n",
            "2659/2659 [==============================] - 34s 13ms/step - loss: 0.1621 - auc: 0.7936 - val_loss: 0.1648 - val_auc: 0.7862\n",
            "Epoch 21/26\n",
            "2659/2659 [==============================] - 34s 13ms/step - loss: 0.1628 - auc: 0.7945 - val_loss: 0.1660 - val_auc: 0.7882\n",
            "Epoch 22/26\n",
            "2659/2659 [==============================] - 34s 13ms/step - loss: 0.1610 - auc: 0.7998 - val_loss: 0.1711 - val_auc: 0.7848\n",
            "Epoch 23/26\n",
            "2659/2659 [==============================] - 36s 14ms/step - loss: 0.1613 - auc: 0.8015 - val_loss: 0.1677 - val_auc: 0.7741\n",
            "Epoch 24/26\n",
            "2659/2659 [==============================] - 35s 13ms/step - loss: 0.1601 - auc: 0.8079 - val_loss: 0.1679 - val_auc: 0.7862\n",
            "Epoch 25/26\n",
            "2659/2659 [==============================] - 34s 13ms/step - loss: 0.1604 - auc: 0.8027 - val_loss: 0.1681 - val_auc: 0.7985\n",
            "Epoch 26/26\n",
            "2659/2659 [==============================] - 33s 13ms/step - loss: 0.1591 - auc: 0.8086 - val_loss: 0.1635 - val_auc: 0.7885\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5d9c06e4c0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import math\n",
        "batch_size = 8\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "#train our model \n",
        "model.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "#the number of epochs \n",
        "    epochs=26,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "Ka-p6mJPJDga"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vT7AAYWhMSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac06719-5c35-41e0-ccd5-ff1384f8d245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 5s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred = model.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred = np.reshape(y_pred, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD9TqoHchMSg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a948be-6b59-4830-ff04-cf44cfc5153f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XawJOc-AhMSh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission 4.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 2**"
      ],
      "metadata": {
        "id": "FJe1eiOOLXmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i change the \"message_calculation_class\" = 'GGNN' Compute new graph states by neural message passing and gated units on the nodes. but by using unbalanced data so we check the accurracy it is not good so we can check another hyperparameaters "
      ],
      "metadata": {
        "id": "ICCVGl_jUVqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "eASbS5s1QwAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tensorflow and other libraries\n",
        "#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n",
        "#import tf2_gnn.layers.message_passing.gnn_edge_mlp\n",
        "from  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean #to calculate segmented mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model #layers and model\n",
        "from tensorflow.keras.layers import Embedding, Dense #layers\n",
        "from tensorflow.keras.optimizers import Adam #optimizer\n",
        "\n",
        "\n",
        "#Input layer for nodes (tokenized text data)          \n",
        "data = keras.Input(batch_shape=(None,)) \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data        \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)   \n",
        "#Input layer for node2graph ids    \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n",
        "#embedding layer over data with each token embedded as  size vector\n",
        "embeded = Embedding(tokenizer.num_words, 75)(data)  \n",
        "\n",
        "# number of graphs (number of samples)\n",
        "#calculating number of samples (or min(batch_size,no._of_samples))  \n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer\n",
        "params[\"hidden_dim\"] = 32 \n",
        "params[\"message_calculation_class\"] = 'GGNN'\n",
        "#params[\"num_edge_MLP_hidden_layers\"] = 16\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "#outpur shape: [data_dimension,hidden layers]  \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )#shape: [batch_size,64] \n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid\n",
        "#Output [None,8]\n",
        "fc1 = Dense(8,activation='relu')(avg) \n",
        "#output shape: [batch_size,1] \n",
        "pred = Dense(1, activation='sigmoid')(fc1)   \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "#inputs are data,edges and node2graph\n",
        "#input: dictionary\n",
        "#output: prediction value from dense layer\n",
        "model_2 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#printing summary of the model\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFQUACLQMMNP",
        "outputId": "abddbb84-b275-498f-dce7-18bd901749fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_1/StatefulPartitionedCall:0', description=\"created by layer 'gnn_1'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_1/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_1'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_2/Sigmoid:0', description=\"created by layer 'dense_2'\")\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOpLamb  ()                  0           ['input_6[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 75)           37500       ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " input_5 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  ()                  0           ['tf.math.reduce_max_1[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_1 (GNN)                    (None, 32)           49568       ['embedding_1[0][0]',            \n",
            "                                                                  'input_5[0][0]',                \n",
            "                                                                  'input_6[0][0]',                \n",
            "                                                                  'tf.__operators__.add_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_1 (TFOpLa  (None, 32)          0           ['gnn_1[0][0]',                  \n",
            " mbda)                                                            'input_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 8)            264         ['tf.math.segment_mean_1[0][0]'] \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            9           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 87,341\n",
            "Trainable params: 87,341\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "2m8IPAB1wZAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile( loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "XNAWokxlMSwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "YqtrUyrhRKt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_2.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59AN7PyeMXnM",
        "outputId": "9ea625cf-c2ef-43ba-9e4c-36fe435e20bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "333/333 [==============================] - 13s 24ms/step - loss: 0.2249 - auc: 0.5342 - val_loss: 0.2035 - val_auc: 0.6297\n",
            "Epoch 2/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1873 - auc: 0.6234 - val_loss: 0.2113 - val_auc: 0.6466\n",
            "Epoch 3/20\n",
            "333/333 [==============================] - 6s 19ms/step - loss: 0.1866 - auc: 0.6367 - val_loss: 0.1880 - val_auc: 0.6893\n",
            "Epoch 4/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1857 - auc: 0.6511 - val_loss: 0.1663 - val_auc: 0.6079\n",
            "Epoch 5/20\n",
            "333/333 [==============================] - 6s 19ms/step - loss: 0.1850 - auc: 0.6481 - val_loss: 0.2061 - val_auc: 0.6428\n",
            "Epoch 6/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1845 - auc: 0.6580 - val_loss: 0.2123 - val_auc: 0.6805\n",
            "Epoch 7/20\n",
            "333/333 [==============================] - 6s 17ms/step - loss: 0.1849 - auc: 0.6640 - val_loss: 0.1743 - val_auc: 0.6115\n",
            "Epoch 8/20\n",
            "333/333 [==============================] - 6s 17ms/step - loss: 0.1823 - auc: 0.6757 - val_loss: 0.1565 - val_auc: 0.7159\n",
            "Epoch 9/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1812 - auc: 0.6788 - val_loss: 0.1787 - val_auc: 0.6930\n",
            "Epoch 10/20\n",
            "333/333 [==============================] - 6s 18ms/step - loss: 0.1796 - auc: 0.6867 - val_loss: 0.1815 - val_auc: 0.7359\n",
            "Epoch 11/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1788 - auc: 0.6927 - val_loss: 0.1802 - val_auc: 0.6740\n",
            "Epoch 12/20\n",
            "333/333 [==============================] - 6s 18ms/step - loss: 0.1777 - auc: 0.7011 - val_loss: 0.1728 - val_auc: 0.7826\n",
            "Epoch 13/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1764 - auc: 0.7048 - val_loss: 0.1792 - val_auc: 0.7284\n",
            "Epoch 14/20\n",
            "333/333 [==============================] - 6s 19ms/step - loss: 0.1748 - auc: 0.7138 - val_loss: 0.1723 - val_auc: 0.7081\n",
            "Epoch 15/20\n",
            "333/333 [==============================] - 5s 15ms/step - loss: 0.1755 - auc: 0.7117 - val_loss: 0.1629 - val_auc: 0.7645\n",
            "Epoch 16/20\n",
            "333/333 [==============================] - 6s 18ms/step - loss: 0.1741 - auc: 0.7220 - val_loss: 0.1830 - val_auc: 0.7238\n",
            "Epoch 17/20\n",
            "333/333 [==============================] - 6s 17ms/step - loss: 0.1733 - auc: 0.7207 - val_loss: 0.1813 - val_auc: 0.7449\n",
            "Epoch 18/20\n",
            "333/333 [==============================] - 5s 15ms/step - loss: 0.1731 - auc: 0.7297 - val_loss: 0.1437 - val_auc: 0.7945\n",
            "Epoch 19/20\n",
            "333/333 [==============================] - 6s 18ms/step - loss: 0.1725 - auc: 0.7320 - val_loss: 0.1834 - val_auc: 0.7459\n",
            "Epoch 20/20\n",
            "333/333 [==============================] - 5s 16ms/step - loss: 0.1707 - auc: 0.7380 - val_loss: 0.1788 - val_auc: 0.7853\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5db036c670>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "Xq-gX-L8RcVz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MG2aqNuRcV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cfd4eb0-8017-40d7-bf2f-28b946ab713a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 5s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_2 = model_2.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_2 = np.reshape(y_pred_2, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc94a73e-927f-4b8e-e3a6-04bfadb06008",
        "id": "47To3O_eRcV1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "len(y_pred_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5KtT-8tRcV2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_2})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_2.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 3**"
      ],
      "metadata": {
        "id": "A9juJqkkVWI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i added hyperparameters\n",
        "num_edge_MLP_hidden_layers by 16  and use message_calculation_class\" = 'RGCN' and another change in the number of a vector space of 50 dimensions in which words will be embedded and in hidden_dim by 64 when i fit the model the accuracy between 68 and 75 so we can check another hyperparameters and check the accurracy "
      ],
      "metadata": {
        "id": "sldUmrBxXcKG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "Eg_5KuzzVcEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tensorflow and other libraries\n",
        "#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n",
        "#import tf2_gnn.layers.message_passing.gnn_edge_mlp\n",
        "from  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean #to calculate segmented mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model #layers and model\n",
        "from tensorflow.keras.layers import Embedding, Dense #layers\n",
        "from tensorflow.keras.optimizers import Adam #optimizer\n",
        "\n",
        "\n",
        "#Input layer for nodes (tokenized text data)          \n",
        "data = keras.Input(batch_shape=(None,)) \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data        \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)   \n",
        "#Input layer for node2graph ids    \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n",
        "#embedding layer over data with each token embedded as  size vector\n",
        "embeded = Embedding(tokenizer.num_words, 50)(data)  \n",
        "\n",
        "# number of graphs (number of samples)\n",
        "#calculating number of samples (or min(batch_size,no._of_samples))  \n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer\n",
        "params[\"hidden_dim\"] = 64\n",
        "#Relational Graph Convolutional Networks  \n",
        "params[\"message_calculation_class\"] = 'RGCN'\n",
        "params[\"num_edge_MLP_hidden_layers\"] = 16\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "#outpur shape: [data_dimension,hidden layers]  \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )#shape: [batch_size,64] \n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid\n",
        "#Output [None,8]\n",
        "fc1 = Dense(8,activation='relu')(avg) \n",
        "#output shape: [batch_size,1] \n",
        "pred = Dense(1, activation='sigmoid')(fc1)   \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "#inputs are data,edges and node2graph\n",
        "#input: dictionary\n",
        "#output: prediction value from dense layer\n",
        "model_3 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#printing summary of the model\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e8f45b-22d2-4bad-ad21-791d887b7fcd",
        "id": "m5dlot-zVcEa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_2/StatefulPartitionedCall:0', description=\"created by layer 'gnn_2'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_2/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_2'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_4/Sigmoid:0', description=\"created by layer 'dense_4'\")\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_2 (TFOpLamb  ()                  0           ['input_9[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, 50)           25000       ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)           [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  ()                  0           ['tf.math.reduce_max_2[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_2 (GNN)                    (None, 64)           335616      ['embedding_2[0][0]',            \n",
            "                                                                  'input_8[0][0]',                \n",
            "                                                                  'input_9[0][0]',                \n",
            "                                                                  'tf.__operators__.add_2[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_2 (TFOpLa  (None, 64)          0           ['gnn_2[0][0]',                  \n",
            " mbda)                                                            'input_9[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 8)            520         ['tf.math.segment_mean_2[0][0]'] \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 1)            9           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 361,145\n",
            "Trainable params: 361,145\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "vFSga8h1wse3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile( loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "1dt93CyxVcEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "FiDOZaDDVcEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_3.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa16d1d-b775-41b2-b739-23dcb28c6986",
        "id": "GU9rXNVRVcEd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "665/665 [==============================] - 32s 28ms/step - loss: 0.3467 - auc: 0.4712 - val_loss: 0.2054 - val_auc: 0.3254\n",
            "Epoch 2/20\n",
            "665/665 [==============================] - 17s 25ms/step - loss: 0.1952 - auc: 0.5299 - val_loss: 0.1893 - val_auc: 0.5425\n",
            "Epoch 3/20\n",
            "665/665 [==============================] - 15s 22ms/step - loss: 0.1927 - auc: 0.5892 - val_loss: 0.1887 - val_auc: 0.6462\n",
            "Epoch 4/20\n",
            "665/665 [==============================] - 15s 22ms/step - loss: 0.1919 - auc: 0.5965 - val_loss: 0.2014 - val_auc: 0.6183\n",
            "Epoch 5/20\n",
            "665/665 [==============================] - 16s 23ms/step - loss: 0.1921 - auc: 0.5917 - val_loss: 0.1956 - val_auc: 0.6002\n",
            "Epoch 6/20\n",
            "665/665 [==============================] - 16s 23ms/step - loss: 0.1914 - auc: 0.5987 - val_loss: 0.1843 - val_auc: 0.6346\n",
            "Epoch 7/20\n",
            "665/665 [==============================] - 16s 24ms/step - loss: 0.1910 - auc: 0.6102 - val_loss: 0.1964 - val_auc: 0.6234\n",
            "Epoch 8/20\n",
            "665/665 [==============================] - 15s 23ms/step - loss: 0.1910 - auc: 0.6137 - val_loss: 0.1829 - val_auc: 0.6211\n",
            "Epoch 9/20\n",
            "665/665 [==============================] - 16s 23ms/step - loss: 0.1912 - auc: 0.6105 - val_loss: 0.2101 - val_auc: 0.6352\n",
            "Epoch 10/20\n",
            "665/665 [==============================] - 16s 23ms/step - loss: 0.1913 - auc: 0.6045 - val_loss: 0.1821 - val_auc: 0.6039\n",
            "Epoch 11/20\n",
            "665/665 [==============================] - 15s 23ms/step - loss: 0.1905 - auc: 0.6122 - val_loss: 0.1878 - val_auc: 0.6406\n",
            "Epoch 12/20\n",
            "665/665 [==============================] - 15s 22ms/step - loss: 0.1906 - auc: 0.6171 - val_loss: 0.1983 - val_auc: 0.6173\n",
            "Epoch 13/20\n",
            "665/665 [==============================] - 15s 22ms/step - loss: 0.1908 - auc: 0.6094 - val_loss: 0.1866 - val_auc: 0.6166\n",
            "Epoch 14/20\n",
            "665/665 [==============================] - 15s 22ms/step - loss: 0.1916 - auc: 0.6098 - val_loss: 0.1980 - val_auc: 0.6575\n",
            "Epoch 15/20\n",
            "665/665 [==============================] - 15s 22ms/step - loss: 0.1923 - auc: 0.5932 - val_loss: 0.1925 - val_auc: 0.6326\n",
            "Epoch 16/20\n",
            "665/665 [==============================] - 16s 23ms/step - loss: 0.1908 - auc: 0.6104 - val_loss: 0.2092 - val_auc: 0.6264\n",
            "Epoch 17/20\n",
            "665/665 [==============================] - 15s 23ms/step - loss: 0.1910 - auc: 0.6159 - val_loss: 0.2050 - val_auc: 0.6368\n",
            "Epoch 18/20\n",
            "665/665 [==============================] - 15s 22ms/step - loss: 0.1908 - auc: 0.6147 - val_loss: 0.1915 - val_auc: 0.6035\n",
            "Epoch 19/20\n",
            "665/665 [==============================] - 15s 22ms/step - loss: 0.1908 - auc: 0.6082 - val_loss: 0.1868 - val_auc: 0.6448\n",
            "Epoch 20/20\n",
            "665/665 [==============================] - 17s 26ms/step - loss: 0.1905 - auc: 0.6184 - val_loss: 0.1968 - val_auc: 0.6488\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5d0a6d19d0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "RlXzOswhVcEg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coMiTD_XVcEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8185355-7b30-452f-cefb-96dd07f0deb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 6s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_3 = model_3.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_3 = np.reshape(y_pred_3, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c907cc-fcce-4fc5-a122-581380318f39",
        "id": "BTKUm-iPVcEh"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "len(y_pred_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxW8zpSKVcEi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_3})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_3.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 4**"
      ],
      "metadata": {
        "id": "4IXmzRV8Xi9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i used \"message_calculation_class\"= \"RGAT\"  and hidden_dim by 32 and num_heads by 32 and after i check the accurracy  and validation accuracy, the accuracy still between 70 and 80 % so we can check by another hyperparameaters "
      ],
      "metadata": {
        "id": "JRr8_lN2dyq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "adXgzA50Xi9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)\n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)\n",
        "embeded = Embedding(tokenizer.num_words, 60)(data)\n",
        "\n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1\n",
        "\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#\"message_calculation_class\" configures the message passing style. \n",
        "# This chooses the tf2_gnn.layers.message_passing.* layer used in each step.\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"hidden_dim\"] = 32 \n",
        "#use GGNN as a calculation class \n",
        "params[\"message_calculation_class\"]= \"RGAT\" \n",
        "params[\"num_heads\"]=32\n",
        "gnn_layer = GNN(params)\n",
        "gnn_out = gnn_layer(gnn_input)\n",
        "\n",
        "print('gnn_out', gnn_out)\n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        ")\n",
        "print('mean:', avg)\n",
        "\n",
        "pred = Dense(1, activation='sigmoid')(avg)\n",
        "print('pred:', pred)\n",
        "# create model \n",
        "model_4 = Model(\n",
        "    inputs={\n",
        "        'data': data,\n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "model_4.summary() "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4e35d2-2428-4bcd-ac57-7e04575b152e",
        "id": "O23OVMMmXi9g"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_3/StatefulPartitionedCall:0', description=\"created by layer 'gnn_3'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_3/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_3'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_5/Sigmoid:0', description=\"created by layer 'dense_5'\")\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_7 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOpLamb  ()                  0           ['input_11[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 60)           30000       ['input_7[0][0]']                \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  ()                  0           ['tf.math.reduce_max_3[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_3 (GNN)                    (None, 32)           24000       ['embedding_3[0][0]',            \n",
            "                                                                  'input_10[0][0]',               \n",
            "                                                                  'input_11[0][0]',               \n",
            "                                                                  'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_3 (TFOpLa  (None, 32)          0           ['gnn_3[0][0]',                  \n",
            " mbda)                                                            'input_11[0][0]']               \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            33          ['tf.math.segment_mean_3[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 54,033\n",
            "Trainable params: 54,033\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "-7ojWP5Gw08u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.compile( loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "sfDhC3CaXi9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "m26_DpZQXi9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 400\n",
        "num_batchs = math.ceil(len(training_set) / batch_size)\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size)\n",
        "\n",
        "model_4.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=40,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=400, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49a5e9b6-68cb-4275-93cb-dd7046f79119",
        "id": "PNtnb5RJXi9l"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "54/54 [==============================] - 29s 159ms/step - loss: 0.6308 - auc: 0.4722 - val_loss: 0.4685 - val_auc: 0.4056\n",
            "Epoch 2/40\n",
            "54/54 [==============================] - 7s 121ms/step - loss: 0.3366 - auc: 0.3966 - val_loss: 0.2847 - val_auc: 0.3592\n",
            "Epoch 3/40\n",
            "54/54 [==============================] - 6s 106ms/step - loss: 0.2799 - auc: 0.3675 - val_loss: 0.2780 - val_auc: 0.3501\n",
            "Epoch 4/40\n",
            "54/54 [==============================] - 7s 122ms/step - loss: 0.2695 - auc: 0.3509 - val_loss: 0.2415 - val_auc: 0.3714\n",
            "Epoch 5/40\n",
            "54/54 [==============================] - 6s 103ms/step - loss: 0.2363 - auc: 0.3807 - val_loss: 0.2361 - val_auc: 0.5516\n",
            "Epoch 6/40\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.2090 - auc: 0.5148 - val_loss: 0.2250 - val_auc: 0.4825\n",
            "Epoch 7/40\n",
            "54/54 [==============================] - 5s 99ms/step - loss: 0.2040 - auc: 0.5414 - val_loss: 0.2065 - val_auc: 0.5326\n",
            "Epoch 8/40\n",
            "54/54 [==============================] - 6s 121ms/step - loss: 0.2006 - auc: 0.5630 - val_loss: 0.2008 - val_auc: 0.5613\n",
            "Epoch 9/40\n",
            "54/54 [==============================] - 5s 98ms/step - loss: 0.1983 - auc: 0.5752 - val_loss: 0.2062 - val_auc: 0.5532\n",
            "Epoch 10/40\n",
            "54/54 [==============================] - 6s 118ms/step - loss: 0.1991 - auc: 0.5697 - val_loss: 0.2071 - val_auc: 0.5616\n",
            "Epoch 11/40\n",
            "54/54 [==============================] - 5s 99ms/step - loss: 0.1958 - auc: 0.5873 - val_loss: 0.1914 - val_auc: 0.6186\n",
            "Epoch 12/40\n",
            "54/54 [==============================] - 6s 119ms/step - loss: 0.1946 - auc: 0.5953 - val_loss: 0.1977 - val_auc: 0.5764\n",
            "Epoch 13/40\n",
            "54/54 [==============================] - 5s 96ms/step - loss: 0.1938 - auc: 0.6012 - val_loss: 0.1895 - val_auc: 0.6269\n",
            "Epoch 14/40\n",
            "54/54 [==============================] - 6s 107ms/step - loss: 0.1935 - auc: 0.6065 - val_loss: 0.1915 - val_auc: 0.6227\n",
            "Epoch 15/40\n",
            "54/54 [==============================] - 6s 108ms/step - loss: 0.1931 - auc: 0.6088 - val_loss: 0.1983 - val_auc: 0.6193\n",
            "Epoch 16/40\n",
            "54/54 [==============================] - 5s 98ms/step - loss: 0.1916 - auc: 0.6165 - val_loss: 0.2083 - val_auc: 0.6453\n",
            "Epoch 17/40\n",
            "54/54 [==============================] - 6s 121ms/step - loss: 0.1917 - auc: 0.6242 - val_loss: 0.1923 - val_auc: 0.6546\n",
            "Epoch 18/40\n",
            "54/54 [==============================] - 5s 99ms/step - loss: 0.1920 - auc: 0.6205 - val_loss: 0.2169 - val_auc: 0.6094\n",
            "Epoch 19/40\n",
            "54/54 [==============================] - 6s 119ms/step - loss: 0.1900 - auc: 0.6368 - val_loss: 0.1879 - val_auc: 0.6635\n",
            "Epoch 20/40\n",
            "54/54 [==============================] - 5s 98ms/step - loss: 0.1887 - auc: 0.6455 - val_loss: 0.1803 - val_auc: 0.6732\n",
            "Epoch 21/40\n",
            "54/54 [==============================] - 6s 117ms/step - loss: 0.1899 - auc: 0.6319 - val_loss: 0.1953 - val_auc: 0.6398\n",
            "Epoch 22/40\n",
            "54/54 [==============================] - 5s 96ms/step - loss: 0.1886 - auc: 0.6444 - val_loss: 0.1827 - val_auc: 0.6655\n",
            "Epoch 23/40\n",
            "54/54 [==============================] - 6s 117ms/step - loss: 0.1886 - auc: 0.6407 - val_loss: 0.1845 - val_auc: 0.6403\n",
            "Epoch 24/40\n",
            "54/54 [==============================] - 5s 97ms/step - loss: 0.1878 - auc: 0.6536 - val_loss: 0.1904 - val_auc: 0.6818\n",
            "Epoch 25/40\n",
            "54/54 [==============================] - 6s 111ms/step - loss: 0.1873 - auc: 0.6527 - val_loss: 0.1792 - val_auc: 0.6617\n",
            "Epoch 26/40\n",
            "54/54 [==============================] - 6s 103ms/step - loss: 0.1861 - auc: 0.6610 - val_loss: 0.1784 - val_auc: 0.6833\n",
            "Epoch 27/40\n",
            "54/54 [==============================] - 5s 96ms/step - loss: 0.1845 - auc: 0.6701 - val_loss: 0.2009 - val_auc: 0.6318\n",
            "Epoch 28/40\n",
            "54/54 [==============================] - 6s 121ms/step - loss: 0.1855 - auc: 0.6587 - val_loss: 0.1822 - val_auc: 0.6816\n",
            "Epoch 29/40\n",
            "54/54 [==============================] - 5s 98ms/step - loss: 0.1855 - auc: 0.6599 - val_loss: 0.1863 - val_auc: 0.6978\n",
            "Epoch 30/40\n",
            "54/54 [==============================] - 6s 119ms/step - loss: 0.1844 - auc: 0.6750 - val_loss: 0.1933 - val_auc: 0.6906\n",
            "Epoch 31/40\n",
            "54/54 [==============================] - 5s 98ms/step - loss: 0.1839 - auc: 0.6723 - val_loss: 0.1935 - val_auc: 0.6723\n",
            "Epoch 32/40\n",
            "54/54 [==============================] - 6s 116ms/step - loss: 0.1832 - auc: 0.6693 - val_loss: 0.1762 - val_auc: 0.6981\n",
            "Epoch 33/40\n",
            "54/54 [==============================] - 5s 97ms/step - loss: 0.1828 - auc: 0.6834 - val_loss: 0.2053 - val_auc: 0.6385\n",
            "Epoch 34/40\n",
            "54/54 [==============================] - 6s 115ms/step - loss: 0.1818 - auc: 0.6835 - val_loss: 0.2068 - val_auc: 0.6380\n",
            "Epoch 35/40\n",
            "54/54 [==============================] - 5s 97ms/step - loss: 0.1816 - auc: 0.6852 - val_loss: 0.1670 - val_auc: 0.7377\n",
            "Epoch 36/40\n",
            "54/54 [==============================] - 5s 102ms/step - loss: 0.1813 - auc: 0.6910 - val_loss: 0.1922 - val_auc: 0.6878\n",
            "Epoch 37/40\n",
            "54/54 [==============================] - 6s 109ms/step - loss: 0.1816 - auc: 0.6867 - val_loss: 0.1724 - val_auc: 0.7174\n",
            "Epoch 38/40\n",
            "54/54 [==============================] - 5s 98ms/step - loss: 0.1817 - auc: 0.6814 - val_loss: 0.1737 - val_auc: 0.7166\n",
            "Epoch 39/40\n",
            "54/54 [==============================] - 6s 116ms/step - loss: 0.1800 - auc: 0.6912 - val_loss: 0.1889 - val_auc: 0.6936\n",
            "Epoch 40/40\n",
            "54/54 [==============================] - 5s 98ms/step - loss: 0.1816 - auc: 0.6837 - val_loss: 0.1776 - val_auc: 0.7043\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5cf8296790>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "SFEGcLTNXi9q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIXIUjsKXi9r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2433e8-f397-4d5e-e93d-7c8f4486cce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 15s 17ms/step\n"
          ]
        }
      ],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_4 = model_4.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_4 = np.reshape(y_pred_4, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDfQNv2xXi9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8c2f8d-95f3-4bd4-a022-1faa4c95563f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "len(y_pred_4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiH4es8KXi9u"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_4})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_4.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 5**"
      ],
      "metadata": {
        "id": "1HiZqdoHYvj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i change in \"message_calculation_class\"] = 'RGIN' and change in another hyperparameaters after i check the accurracy it between 70 and 80 % so we can check by another hyperparameaters "
      ],
      "metadata": {
        "id": "hJGPcdfWZi36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "lYhl5ue9Yvj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tensorflow and other libraries\n",
        "#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n",
        "#import tf2_gnn.layers.message_passing.gnn_edge_mlp\n",
        "from  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean #to calculate segmented mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model #layers and model\n",
        "from tensorflow.keras.layers import Embedding, Dense #layers\n",
        "from tensorflow.keras.optimizers import Adam #optimizer\n",
        "\n",
        "\n",
        "#Input layer for nodes (tokenized text data)          \n",
        "data = keras.Input(batch_shape=(None,)) \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data        \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)   \n",
        "#Input layer for node2graph ids    \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n",
        "#embedding layer over data with each token embedded as  size vector\n",
        "embeded = Embedding(tokenizer.num_words, 150)(data)  \n",
        "\n",
        "# number of graphs (number of samples)\n",
        "#calculating number of samples (or min(batch_size,no._of_samples))  \n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer\n",
        "params[\"hidden_dim\"] = 50\n",
        "#Relational Graph Isomorphism Networks \n",
        "params[\"message_calculation_class\"] = 'RGIN'\n",
        "params[\"num_edge_MLP_hidden_layers\"] = 32 ##\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "#outpur shape: [data_dimension,hidden layers]  \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )#shape: [batch_size,64] \n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid\n",
        "#Output [None,8]\n",
        "fc1 = Dense(8,activation='relu')(avg) \n",
        "#output shape: [batch_size,1] \n",
        "pred = Dense(1, activation='sigmoid')(fc1)   \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "#inputs are data,edges and node2graph\n",
        "#input: dictionary\n",
        "#output: prediction value from dense layer\n",
        "model_5 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#printing summary of the model\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3754d957-a9ec-4a8d-f939-8ca53fd275fa",
        "id": "5-XyYgVQYvj7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_3/StatefulPartitionedCall:0', description=\"created by layer 'gnn_3'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_3/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_3'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_5/Sigmoid:0', description=\"created by layer 'dense_5'\")\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOpLamb  ()                  0           ['input_12[0][0]']               \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 75)           37500       ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  ()                  0           ['tf.math.reduce_max_3[0][0]']   \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " gnn_3 (GNN)                    (None, 32)           49568       ['embedding_3[0][0]',            \n",
            "                                                                  'input_11[0][0]',               \n",
            "                                                                  'input_12[0][0]',               \n",
            "                                                                  'tf.__operators__.add_3[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.segment_mean_3 (TFOpLa  (None, 32)          0           ['gnn_3[0][0]',                  \n",
            " mbda)                                                            'input_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 8)            264         ['tf.math.segment_mean_3[0][0]'] \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            9           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 87,341\n",
            "Trainable params: 87,341\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "oUR240xAw83y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.compile( loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "yaPBjUy_Yvj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "Cc45PxcXYvj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_5.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec78db71-0c36-4e0b-89d7-c5736da61b40",
        "id": "jUysWoZCYvj-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn_3/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn_3/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn_3/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn_2/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn_2/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn_2/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn_1/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn_1/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn_1/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:446: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/ggnn/embedding_lookup_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/ggnn/embedding_lookup_grad/Reshape:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradients/ggnn/embedding_lookup_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "333/333 [==============================] - 21s 48ms/step - loss: 0.2035 - auc: 0.5818 - val_loss: 0.1738 - val_auc: 0.6971\n",
            "Epoch 2/20\n",
            "333/333 [==============================] - 13s 39ms/step - loss: 0.1853 - auc: 0.6527 - val_loss: 0.2159 - val_auc: 0.6590\n",
            "Epoch 3/20\n",
            "333/333 [==============================] - 14s 42ms/step - loss: 0.1826 - auc: 0.6702 - val_loss: 0.1593 - val_auc: 0.7007\n",
            "Epoch 4/20\n",
            "333/333 [==============================] - 11s 35ms/step - loss: 0.1820 - auc: 0.6720 - val_loss: 0.1662 - val_auc: 0.7348\n",
            "Epoch 5/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1789 - auc: 0.6963 - val_loss: 0.1573 - val_auc: 0.6940\n",
            "Epoch 6/20\n",
            "333/333 [==============================] - 12s 35ms/step - loss: 0.1769 - auc: 0.7051 - val_loss: 0.2160 - val_auc: 0.7162\n",
            "Epoch 7/20\n",
            "333/333 [==============================] - 15s 47ms/step - loss: 0.1746 - auc: 0.7209 - val_loss: 0.2088 - val_auc: 0.7885\n",
            "Epoch 8/20\n",
            "333/333 [==============================] - 13s 39ms/step - loss: 0.1728 - auc: 0.7329 - val_loss: 0.1708 - val_auc: 0.7275\n",
            "Epoch 9/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1707 - auc: 0.7435 - val_loss: 0.1721 - val_auc: 0.7992\n",
            "Epoch 10/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1703 - auc: 0.7506 - val_loss: 0.1918 - val_auc: 0.6650\n",
            "Epoch 11/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1682 - auc: 0.7660 - val_loss: 0.1816 - val_auc: 0.7570\n",
            "Epoch 12/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1679 - auc: 0.7598 - val_loss: 0.1854 - val_auc: 0.7161\n",
            "Epoch 13/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1668 - auc: 0.7698 - val_loss: 0.1900 - val_auc: 0.6939\n",
            "Epoch 14/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1663 - auc: 0.7729 - val_loss: 0.1550 - val_auc: 0.8007\n",
            "Epoch 15/20\n",
            "333/333 [==============================] - 12s 35ms/step - loss: 0.1631 - auc: 0.7831 - val_loss: 0.1554 - val_auc: 0.8011\n",
            "Epoch 16/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1622 - auc: 0.7894 - val_loss: 0.1966 - val_auc: 0.7657\n",
            "Epoch 17/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1611 - auc: 0.7895 - val_loss: 0.1512 - val_auc: 0.8249\n",
            "Epoch 18/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1597 - auc: 0.7949 - val_loss: 0.1834 - val_auc: 0.7505\n",
            "Epoch 19/20\n",
            "333/333 [==============================] - 12s 35ms/step - loss: 0.1576 - auc: 0.8009 - val_loss: 0.1669 - val_auc: 0.7975\n",
            "Epoch 20/20\n",
            "333/333 [==============================] - 11s 34ms/step - loss: 0.1575 - auc: 0.8062 - val_loss: 0.1641 - val_auc: 0.7896\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6315cc4590>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "6WMuTu-GYvj_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67wprhPxYvkA"
      },
      "outputs": [],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_5 = model_5.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_5 = np.reshape(y_pred_5, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daeda023-f400-4c05-8fa2-f02f5877a8d2",
        "id": "l29-K92dYvkA"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "len(y_pred_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxxhESMCYvkB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_5})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_5.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Solve Unbalanced Data** "
      ],
      "metadata": {
        "id": "aFvb6qK065Xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "#read the training data as a dataframe\n",
        "df = pd.DataFrame(training_set,columns=['Nodes','Edges','Labels']) \n",
        "df_majority = df[df['Labels']==0]  #data with majority class\n",
        "df_minority = df[df['Labels']==1]  #data with maniority class\n",
        "\n",
        "print('Shape of Unbalanced Data before Upsampling:')\n",
        "print(df_majority.shape)\n",
        "print(df_minority .shape)\n",
        "print('\\n')\n",
        "\n",
        "# Upsample minority class\n",
        "df_minority_upsampled = resample(df_minority,\n",
        "                                  # sample with replacement \n",
        "                                 replace=True, \n",
        "                                 # to match majority class                 \n",
        "                                 n_samples=len(df_majority),\n",
        "                                  # reproducible results     \n",
        "                                 random_state=42)               \n",
        "\n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
        "\n",
        "# Display new class counts\n",
        "print('New class counts after Upsampling:')\n",
        "df_upsampled['Labels'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54O_g_it7H9R",
        "outputId": "a9372dce-8916-40ba-a80d-06b0543bba39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Unbalanced Data before Upsampling:\n",
            "(20235, 3)\n",
            "(20235, 3)\n",
            "\n",
            "\n",
            "New class counts after Upsampling:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    20235\n",
              "1    20235\n",
              "Name: Labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the dataframe of data to numpy array so we can deal with\n",
        "training_set= df_upsampled.to_numpy()"
      ],
      "metadata": {
        "id": "uXWIFQvm7Z4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 6 With Balanced Data**"
      ],
      "metadata": {
        "id": "5i6mQwABZf9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The GNN layer takes a GNNInput named tuple as input, which encapsulates:\n",
        "\n",
        "  1) Initial node features\n",
        "\n",
        "  2) Adjacency lists\n",
        "\n",
        "  3) Auxiliary information\n",
        "\n",
        "In this trial we will use   \"message_calculation_class\": \"gnn_edge_mlp\" which configures the message passing style\n",
        "\n",
        "the accuracy improved and became between 80 and 97 % \n"
      ],
      "metadata": {
        "id": "JL0Y9Rsmekmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "HaUDsB_4Zf9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model \n",
        "from tensorflow.keras.layers import Embedding, Dense \n",
        "from tensorflow.keras.optimizers import Adam \n",
        "\n",
        "#identify the 4 GNNInput inputs(data, edge, node2graph, num_graph)\n",
        "data = keras.Input(batch_shape=(None,))                           #Input layer for nodes (tokenized text data)            \n",
        "embeded = Embedding(tokenizer.num_words, 100)(data)               #embedding layer over data with each token embedded as  size vector \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)         #Input layer for edge data         \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)     #Input layer for node2graph ids    \n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1                           #number of graphs (number of samples) \n",
        "\n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"hidden_dim\"] = 64 \n",
        "#defining hidden dimension of the gnn layer(the output of all message passing layers)                   \n",
        "params[\"message_calculation_class\"] = 'gnn_edge_mlp'\n",
        "params[\"num_aggr_MLP_hidden_layers\"] = 4\n",
        "\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )                                     \n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid activation function\n",
        "pred = Dense(1, activation='sigmoid')(avg)    \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "# input : dictionary of data,edges and node2graph\n",
        "# output: prediction value from dense layer\n",
        "\n",
        "model_6 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#display model summary \n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04056678-ef61-4a3d-d614-c1a1b0272dac",
        "id": "qUp9LjyiZf9K"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_26/StatefulPartitionedCall:0', description=\"created by layer 'gnn_26'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_5/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_5'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_7/Sigmoid:0', description=\"created by layer 'dense_7'\")\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_80 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_78 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_26 (TFOpLam  ()                  0           ['input_80[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_26 (Embedding)       (None, 100)          50000       ['input_78[0][0]']               \n",
            "                                                                                                  \n",
            " input_79 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_26 (TFOpL  ()                  0           ['tf.math.reduce_max_26[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_26 (GNN)                   (None, 64)           76672       ['embedding_26[0][0]',           \n",
            "                                                                  'input_79[0][0]',               \n",
            "                                                                  'input_80[0][0]',               \n",
            "                                                                  'tf.__operators__.add_26[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_5 (TFOpLa  (None, 64)          0           ['gnn_26[0][0]',                 \n",
            " mbda)                                                            'input_80[0][0]']               \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 1)            65          ['tf.math.segment_mean_5[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 126,737\n",
            "Trainable params: 126,737\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "W4qhgL6QxGe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.compile(optimizer='adam', loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "jFgRqiMUZf9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "6QQMjtZzZf9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_6.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9713e1be-c45f-434a-d629-5f92e7a6bd38",
        "id": "pCGMHj3vZf9M"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2530/2530 [==============================] - 39s 14ms/step - loss: 0.6045 - auc: 0.7361 - val_loss: 0.5700 - val_auc: 0.7437\n",
            "Epoch 2/20\n",
            "2530/2530 [==============================] - 33s 13ms/step - loss: 0.5660 - auc: 0.7776 - val_loss: 0.5752 - val_auc: 0.7766\n",
            "Epoch 3/20\n",
            "2530/2530 [==============================] - 34s 13ms/step - loss: 0.5342 - auc: 0.8076 - val_loss: 0.5342 - val_auc: 0.7901\n",
            "Epoch 4/20\n",
            "2530/2530 [==============================] - 32s 13ms/step - loss: 0.5058 - auc: 0.8328 - val_loss: 0.5059 - val_auc: 0.8055\n",
            "Epoch 5/20\n",
            "2530/2530 [==============================] - 32s 13ms/step - loss: 0.4721 - auc: 0.8577 - val_loss: 0.5742 - val_auc: 0.8151\n",
            "Epoch 6/20\n",
            "2530/2530 [==============================] - 32s 12ms/step - loss: 0.4438 - auc: 0.8753 - val_loss: 0.6598 - val_auc: 0.7988\n",
            "Epoch 7/20\n",
            "2530/2530 [==============================] - 33s 13ms/step - loss: 0.4164 - auc: 0.8908 - val_loss: 0.4483 - val_auc: 0.8135\n",
            "Epoch 8/20\n",
            "2530/2530 [==============================] - 32s 12ms/step - loss: 0.3931 - auc: 0.9030 - val_loss: 0.5090 - val_auc: 0.8111\n",
            "Epoch 9/20\n",
            "2530/2530 [==============================] - 33s 13ms/step - loss: 0.3757 - auc: 0.9115 - val_loss: 0.4214 - val_auc: 0.8143\n",
            "Epoch 10/20\n",
            "2530/2530 [==============================] - 33s 13ms/step - loss: 0.3572 - auc: 0.9204 - val_loss: 0.5103 - val_auc: 0.7998\n",
            "Epoch 11/20\n",
            "2530/2530 [==============================] - 33s 13ms/step - loss: 0.3411 - auc: 0.9273 - val_loss: 0.5250 - val_auc: 0.8001\n",
            "Epoch 12/20\n",
            "2530/2530 [==============================] - 32s 13ms/step - loss: 0.3289 - auc: 0.9324 - val_loss: 0.5256 - val_auc: 0.8114\n",
            "Epoch 13/20\n",
            "2530/2530 [==============================] - 32s 13ms/step - loss: 0.3114 - auc: 0.9393 - val_loss: 0.5176 - val_auc: 0.8288\n",
            "Epoch 14/20\n",
            "2530/2530 [==============================] - 33s 13ms/step - loss: 0.2991 - auc: 0.9434 - val_loss: 0.3886 - val_auc: 0.7927\n",
            "Epoch 15/20\n",
            "2530/2530 [==============================] - 32s 13ms/step - loss: 0.2881 - auc: 0.9475 - val_loss: 0.4542 - val_auc: 0.8143\n",
            "Epoch 16/20\n",
            "2530/2530 [==============================] - 33s 13ms/step - loss: 0.2781 - auc: 0.9512 - val_loss: 0.4245 - val_auc: 0.8002\n",
            "Epoch 17/20\n",
            "2530/2530 [==============================] - 32s 12ms/step - loss: 0.2683 - auc: 0.9541 - val_loss: 0.5586 - val_auc: 0.7871\n",
            "Epoch 18/20\n",
            "2530/2530 [==============================] - 33s 13ms/step - loss: 0.2623 - auc: 0.9563 - val_loss: 0.4493 - val_auc: 0.7804\n",
            "Epoch 19/20\n",
            "2530/2530 [==============================] - 33s 13ms/step - loss: 0.2555 - auc: 0.9586 - val_loss: 0.5489 - val_auc: 0.7962\n",
            "Epoch 20/20\n",
            "2530/2530 [==============================] - 33s 13ms/step - loss: 0.2526 - auc: 0.9592 - val_loss: 0.6085 - val_auc: 0.7977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5c9ac2f2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "1QdUTEbZZf9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDTjXF5VZf9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6eec858-f55f-49b5-ba28-13dd722cdd27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 4s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_6 = model_6.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_6 = np.reshape(y_pred_6, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ad2b88-badf-4678-a038-365dbe06d6a2",
        "id": "ahyovT8AZf9N"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "len(y_pred_6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AijQu8PPZf9O"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_6})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_6.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 7 With Balanced Data**"
      ],
      "metadata": {
        "id": "IdxF4TOKa6WY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i used \"message_calculation_class\"] ='GNN_FiLM'\n",
        "and \"film_parameter_MLP_hidden_layers\" by 1   the accuracy became between 90 and 98 % so this is the best model "
      ],
      "metadata": {
        "id": "PkY-xHaCfUSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "oMpGhSnwa6WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model \n",
        "from tensorflow.keras.layers import Embedding, Dense \n",
        "from tensorflow.keras.optimizers import Adam \n",
        "\n",
        "#identify the 4 GNNInput inputs(data, edge, node2graph, num_graph)\n",
        "#Input layer for nodes (tokenized text data)\n",
        "data = keras.Input(batch_shape=(None,))\n",
        "#embedding layer over data with each token embedded as  size vector \n",
        "#the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "embeded = Embedding(tokenizer.num_words, 100)(data)              \n",
        "#Input layer for edge data \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)         \n",
        "#Input layer for node2graph ids         \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)        \n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1                           \n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "params[\"hidden_dim\"] = 64\n",
        "#defining hidden dimension of the gnn layer(the output of all message passing layers)\n",
        "params[\"film_parameter_MLP_hidden_layers\"] = 1\n",
        "params[\"message_calculation_class\"] ='GNN_FiLM'\n",
        "\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )                                     \n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid activation function\n",
        "pred = Dense(1, activation='sigmoid')(avg)    \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "\"\"\"\n",
        "input : dictionary of data,edges and node2graph\n",
        "output: prediction value from dense layer\n",
        "\"\"\"\n",
        "model_7 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#display model summary \n",
        "model_7.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b74472-3466-4671-a46f-9deba4df4ec3",
        "id": "vsJQ7_4Ra6Wa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_27/StatefulPartitionedCall:0', description=\"created by layer 'gnn_27'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_6/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_6'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_8/Sigmoid:0', description=\"created by layer 'dense_8'\")\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_83 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_81 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_27 (TFOpLam  ()                  0           ['input_83[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_27 (Embedding)       (None, 100)          50000       ['input_81[0][0]']               \n",
            "                                                                                                  \n",
            " input_82 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_27 (TFOpL  ()                  0           ['tf.math.reduce_max_27[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_27 (GNN)                   (None, 64)           174976      ['embedding_27[0][0]',           \n",
            "                                                                  'input_82[0][0]',               \n",
            "                                                                  'input_83[0][0]',               \n",
            "                                                                  'tf.__operators__.add_27[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_6 (TFOpLa  (None, 64)          0           ['gnn_27[0][0]',                 \n",
            " mbda)                                                            'input_83[0][0]']               \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 1)            65          ['tf.math.segment_mean_6[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 225,041\n",
            "Trainable params: 225,041\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "AWiq6Ei-xP6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.compile(optimizer='adam',loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "ZraMVZu_a6Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "Em2pqeWxa6Wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "batch_size = 32\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_7.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5f099e-9b7a-4fa4-8ea6-ba56cc548c1d",
        "id": "yHuhQHU8a6Wd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1265/1265 [==============================] - 30s 19ms/step - loss: 0.5849 - auc: 0.7574 - val_loss: 0.9076 - val_auc: 0.7283\n",
            "Epoch 2/20\n",
            "1265/1265 [==============================] - 20s 16ms/step - loss: 0.5091 - auc: 0.8301 - val_loss: 0.6614 - val_auc: 0.8189\n",
            "Epoch 3/20\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.4738 - auc: 0.8559 - val_loss: 0.5664 - val_auc: 0.8218\n",
            "Epoch 4/20\n",
            "1265/1265 [==============================] - 20s 16ms/step - loss: 0.4301 - auc: 0.8830 - val_loss: 0.4605 - val_auc: 0.8501\n",
            "Epoch 5/20\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.3964 - auc: 0.9022 - val_loss: 0.4409 - val_auc: 0.8719\n",
            "Epoch 6/20\n",
            "1265/1265 [==============================] - 20s 16ms/step - loss: 0.3605 - auc: 0.9199 - val_loss: 0.5130 - val_auc: 0.8096\n",
            "Epoch 7/20\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.3239 - auc: 0.9352 - val_loss: 0.3791 - val_auc: 0.8279\n",
            "Epoch 8/20\n",
            "1265/1265 [==============================] - 20s 16ms/step - loss: 0.2958 - auc: 0.9456 - val_loss: 0.5417 - val_auc: 0.8634\n",
            "Epoch 9/20\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.2765 - auc: 0.9525 - val_loss: 0.5276 - val_auc: 0.8477\n",
            "Epoch 10/20\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.2515 - auc: 0.9603 - val_loss: 0.5797 - val_auc: 0.8334\n",
            "Epoch 11/20\n",
            "1265/1265 [==============================] - 21s 17ms/step - loss: 0.2419 - auc: 0.9628 - val_loss: 0.3919 - val_auc: 0.8371\n",
            "Epoch 12/20\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.2249 - auc: 0.9676 - val_loss: 0.4534 - val_auc: 0.8514\n",
            "Epoch 13/20\n",
            "1265/1265 [==============================] - 20s 16ms/step - loss: 0.2112 - auc: 0.9710 - val_loss: 0.3948 - val_auc: 0.8155\n",
            "Epoch 14/20\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.1994 - auc: 0.9737 - val_loss: 0.4608 - val_auc: 0.8483\n",
            "Epoch 15/20\n",
            "1265/1265 [==============================] - 20s 16ms/step - loss: 0.1936 - auc: 0.9751 - val_loss: 0.3573 - val_auc: 0.8358\n",
            "Epoch 16/20\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.1829 - auc: 0.9776 - val_loss: 0.4308 - val_auc: 0.8838\n",
            "Epoch 17/20\n",
            "1265/1265 [==============================] - 20s 16ms/step - loss: 0.1787 - auc: 0.9787 - val_loss: 0.3337 - val_auc: 0.8224\n",
            "Epoch 18/20\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.1756 - auc: 0.9791 - val_loss: 0.4736 - val_auc: 0.8201\n",
            "Epoch 19/20\n",
            "1265/1265 [==============================] - 20s 16ms/step - loss: 0.1629 - auc: 0.9815 - val_loss: 0.3687 - val_auc: 0.7931\n",
            "Epoch 20/20\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.1632 - auc: 0.9815 - val_loss: 0.4721 - val_auc: 0.8499\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5ccd7f9040>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "YD-PyevTa6We"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjeZET1Fa6Wf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36e5b8b-f103-4c67-87af-2be3b39de19f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 4s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_7 = model_7.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_7 = np.reshape(y_pred_7, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be406dd-3e63-40ff-f10e-55da0e6d194e",
        "id": "cTT9AU69a6Wf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "len(y_pred_7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfdD5-6ya6Wg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_7})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_7.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 8 With Balanced Data**"
      ],
      "metadata": {
        "id": "EoMtjEyS5L7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i used last \"message_calculation_class\"] ='GNN_FiLM' but different hyperparameaters and after i check the accurracy it began by 82 and increase until 95 and decrease again to 75 % "
      ],
      "metadata": {
        "id": "89UJ8fbUf7X5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "R7vVAyKw5L7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model \n",
        "from tensorflow.keras.layers import Embedding, Dense \n",
        "from tensorflow.keras.optimizers import Adam \n",
        "\n",
        "\n",
        "#identify the 4 GNNInput inputs(data, edge, node2graph, num_graph)\n",
        "#Input layer for nodes (tokenized text data)\n",
        "data = keras.Input(batch_shape=(None,))  \n",
        "#embedding layer over data with each token embedded as  size vector                                      \n",
        "embeded = Embedding(tokenizer.num_words, 100)(data)               \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)         \n",
        "#Input layer for node2graph ids        \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32)         \n",
        "# number of graphs (number of samples)\n",
        "num_graph = tf.reduce_max(node2graph)+1                           \n",
        "\n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer(the output of all message passing layers)\n",
        "params[\"hidden_dim\"] = 40\n",
        "params[\"film_parameter_MLP_hidden_layers\"] = 1\n",
        "params[\"message_calculation_class\"] ='GNN_FiLM'\n",
        "\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )                                     \n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid activation function\n",
        "pred = Dense(1, activation='sigmoid')(avg)    \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "# input : dictionary of data,edges and node2graph\n",
        "# output: prediction value from dense layer\n",
        "\n",
        "model_8 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#display model summary \n",
        "model_8.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b07abc-4fab-4dd7-f2f8-ac97c46ff17d",
        "id": "g_mzYT4u5L7D"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='gnn_28/StatefulPartitionedCall:0', description=\"created by layer 'gnn_28'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), name='tf.math.segment_mean_7/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_7'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_9/Sigmoid:0', description=\"created by layer 'dense_9'\")\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_86 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_84 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_28 (TFOpLam  ()                  0           ['input_86[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_28 (Embedding)       (None, 100)          50000       ['input_84[0][0]']               \n",
            "                                                                                                  \n",
            " input_85 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_28 (TFOpL  ()                  0           ['tf.math.reduce_max_28[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_28 (GNN)                   (None, 40)           73840       ['embedding_28[0][0]',           \n",
            "                                                                  'input_85[0][0]',               \n",
            "                                                                  'input_86[0][0]',               \n",
            "                                                                  'tf.__operators__.add_28[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_7 (TFOpLa  (None, 40)          0           ['gnn_28[0][0]',                 \n",
            " mbda)                                                            'input_86[0][0]']               \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1)            41          ['tf.math.segment_mean_7[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 123,881\n",
            "Trainable params: 123,881\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "snxwaG385L7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_8.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss='BinaryCrossentropy',\n",
        "    metrics=['AUC'])"
      ],
      "metadata": {
        "id": "Ac8tX-UL5L7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "Qb7iN2Wr5L7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "num_batchs            = math.ceil(len(training_set) / batch_size)   #no. of batches for training data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) #no. of batches for validation data\n",
        "\n",
        "model_8.fit(\n",
        "    gen_batch(training_set, batch_size=batch_size, repeat=True),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    validation_data=gen_batch(validation_set, batch_size=batch_size, repeat=True),\n",
        "    validation_steps=num_batchs_validation,\n",
        "     epochs=35,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d38f6a7-e4f1-4233-e7fe-d15214bf0aab",
        "id": "Pd5Rl4RF5L7F"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "1265/1265 [==============================] - 29s 18ms/step - loss: 0.5859 - auc: 0.7560 - val_loss: 0.5835 - val_auc: 0.8127\n",
            "Epoch 2/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.4958 - auc: 0.8402 - val_loss: 0.6525 - val_auc: 0.8306\n",
            "Epoch 3/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.4490 - auc: 0.8725 - val_loss: 0.5610 - val_auc: 0.8362\n",
            "Epoch 4/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.4109 - auc: 0.8946 - val_loss: 0.5160 - val_auc: 0.8523\n",
            "Epoch 5/35\n",
            "1265/1265 [==============================] - 18s 15ms/step - loss: 0.3887 - auc: 0.9066 - val_loss: 0.5438 - val_auc: 0.8497\n",
            "Epoch 6/35\n",
            "1265/1265 [==============================] - 21s 17ms/step - loss: 0.3552 - auc: 0.9224 - val_loss: 0.5065 - val_auc: 0.8483\n",
            "Epoch 7/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.3335 - auc: 0.9311 - val_loss: 0.4380 - val_auc: 0.8593\n",
            "Epoch 8/35\n",
            "1265/1265 [==============================] - 20s 16ms/step - loss: 0.3163 - auc: 0.9380 - val_loss: 0.4540 - val_auc: 0.8518\n",
            "Epoch 9/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.2984 - auc: 0.9447 - val_loss: 0.4496 - val_auc: 0.8540\n",
            "Epoch 10/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.2776 - auc: 0.9518 - val_loss: 0.3104 - val_auc: 0.8429\n",
            "Epoch 11/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.2665 - auc: 0.9553 - val_loss: 0.4725 - val_auc: 0.8722\n",
            "Epoch 12/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.2541 - auc: 0.9590 - val_loss: 0.4441 - val_auc: 0.8535\n",
            "Epoch 13/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.2476 - auc: 0.9613 - val_loss: 0.4527 - val_auc: 0.8412\n",
            "Epoch 14/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.2348 - auc: 0.9646 - val_loss: 0.4292 - val_auc: 0.8431\n",
            "Epoch 15/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.2258 - auc: 0.9675 - val_loss: 0.4233 - val_auc: 0.8521\n",
            "Epoch 16/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.2171 - auc: 0.9693 - val_loss: 0.3971 - val_auc: 0.8339\n",
            "Epoch 17/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.2041 - auc: 0.9726 - val_loss: 0.3674 - val_auc: 0.8520\n",
            "Epoch 18/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.2053 - auc: 0.9722 - val_loss: 0.4745 - val_auc: 0.8514\n",
            "Epoch 19/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.1998 - auc: 0.9736 - val_loss: 0.4032 - val_auc: 0.8323\n",
            "Epoch 20/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.1955 - auc: 0.9745 - val_loss: 0.3161 - val_auc: 0.8180\n",
            "Epoch 21/35\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.1843 - auc: 0.9771 - val_loss: 0.3956 - val_auc: 0.8523\n",
            "Epoch 22/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.1782 - auc: 0.9782 - val_loss: 0.4506 - val_auc: 0.8484\n",
            "Epoch 23/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.1735 - auc: 0.9792 - val_loss: 0.3798 - val_auc: 0.8254\n",
            "Epoch 24/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.1741 - auc: 0.9793 - val_loss: 0.3630 - val_auc: 0.8484\n",
            "Epoch 25/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.1627 - auc: 0.9812 - val_loss: 0.4542 - val_auc: 0.8284\n",
            "Epoch 26/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.1684 - auc: 0.9805 - val_loss: 0.3305 - val_auc: 0.8415\n",
            "Epoch 27/35\n",
            "1265/1265 [==============================] - 18s 14ms/step - loss: 0.1688 - auc: 0.9805 - val_loss: 0.3641 - val_auc: 0.8479\n",
            "Epoch 28/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.1563 - auc: 0.9828 - val_loss: 0.3894 - val_auc: 0.8471\n",
            "Epoch 29/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.1626 - auc: 0.9818 - val_loss: 0.3962 - val_auc: 0.8465\n",
            "Epoch 30/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.1592 - auc: 0.9818 - val_loss: 0.4059 - val_auc: 0.8561\n",
            "Epoch 31/35\n",
            "1265/1265 [==============================] - 20s 16ms/step - loss: 0.1584 - auc: 0.9823 - val_loss: 0.3981 - val_auc: 0.8403\n",
            "Epoch 32/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.1546 - auc: 0.9828 - val_loss: 0.3629 - val_auc: 0.8406\n",
            "Epoch 33/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.1429 - auc: 0.9850 - val_loss: 0.3731 - val_auc: 0.8234\n",
            "Epoch 34/35\n",
            "1265/1265 [==============================] - 19s 15ms/step - loss: 0.1408 - auc: 0.9854 - val_loss: 0.3683 - val_auc: 0.8604\n",
            "Epoch 35/35\n",
            "1265/1265 [==============================] - 18s 15ms/step - loss: 0.1400 - auc: 0.9854 - val_loss: 0.3684 - val_auc: 0.8123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5ccd7fae80>"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "-QjL1LIw5L7G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6XYYEpe5L7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0327a965-eef4-48f5-f57a-535ec1a10755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 5s 5ms/step\n"
          ]
        }
      ],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_8 = model_8.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_8 = np.reshape(y_pred_8, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b727fb18-1d21-4a60-cb70-1cf1b0992e9b",
        "id": "wyDSNHXA5L7H"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "len(y_pred_8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XYx9oDg5L7H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_8})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_8.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 9 With Balanced Data** "
      ],
      "metadata": {
        "id": "fBPxbkSOKIVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i used as the second trial but after balance the data so the accurracy became between 80 and 95 % but not stables "
      ],
      "metadata": {
        "id": "jtPlQ0_kghh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "i3bPJr1dKDUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tensorflow and other libraries\n",
        "#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n",
        "#import tf2_gnn.layers.message_passing.gnn_edge_mlp\n",
        "from  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean #to calculate segmented mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model #layers and model\n",
        "from tensorflow.keras.layers import Embedding, Dense #layers\n",
        "from tensorflow.keras.optimizers import Adam #optimizer\n",
        "\n",
        "\n",
        "#Input layer for nodes (tokenized text data)          \n",
        "data = keras.Input(batch_shape=(None,)) \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data        \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)   \n",
        "#Input layer for node2graph ids    \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n",
        "#embedding layer over data with each token embedded as  size vector\n",
        "embeded = Embedding(tokenizer.num_words, 75)(data)  \n",
        "\n",
        "# number of graphs (number of samples)\n",
        "#calculating number of samples (or min(batch_size,no._of_samples))  \n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer\n",
        "params[\"hidden_dim\"] = 32 \n",
        "params[\"message_calculation_class\"] = 'GGNN'\n",
        "#params[\"num_edge_MLP_hidden_layers\"] = 16\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "#outpur shape: [data_dimension,hidden layers]  \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )#shape: [batch_size,64] \n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid\n",
        "#Output [None,8]\n",
        "fc1 = Dense(8,activation='relu')(avg) \n",
        "#output shape: [batch_size,1] \n",
        "pred = Dense(1, activation='sigmoid')(fc1)   \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "#inputs are data,edges and node2graph\n",
        "#input: dictionary\n",
        "#output: prediction value from dense layer\n",
        "model_9 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#printing summary of the model\n",
        "model_9.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836f0a30-48d6-4551-af15-f35889eced74",
        "id": "IKSKgiCpKDUM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='gnn_29/StatefulPartitionedCall:0', description=\"created by layer 'gnn_29'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='tf.math.segment_mean_8/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_8'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_11/Sigmoid:0', description=\"created by layer 'dense_11'\")\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_89 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_87 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_29 (TFOpLam  ()                  0           ['input_89[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_29 (Embedding)       (None, 75)           37500       ['input_87[0][0]']               \n",
            "                                                                                                  \n",
            " input_88 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_29 (TFOpL  ()                  0           ['tf.math.reduce_max_29[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_29 (GNN)                   (None, 32)           49568       ['embedding_29[0][0]',           \n",
            "                                                                  'input_88[0][0]',               \n",
            "                                                                  'input_89[0][0]',               \n",
            "                                                                  'tf.__operators__.add_29[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_8 (TFOpLa  (None, 32)          0           ['gnn_29[0][0]',                 \n",
            " mbda)                                                            'input_89[0][0]']               \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 8)            264         ['tf.math.segment_mean_8[0][0]'] \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 1)            9           ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 87,341\n",
            "Trainable params: 87,341\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "D2LUjuJHKDUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_9.compile(optimizer='adam',loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "XDP5dGy8KDUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "97QQYduCKDUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_9.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24287bd4-d908-4b07-f355-fdea2c96cd5c",
        "id": "9MeARrFbKDUQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "633/633 [==============================] - 22s 23ms/step - loss: 0.6338 - auc: 0.6892 - val_loss: 0.8585 - val_auc: 0.7604\n",
            "Epoch 2/20\n",
            "633/633 [==============================] - 11s 18ms/step - loss: 0.5916 - auc: 0.7455 - val_loss: 0.7306 - val_auc: 0.7319\n",
            "Epoch 3/20\n",
            "633/633 [==============================] - 11s 18ms/step - loss: 0.5604 - auc: 0.7834 - val_loss: 0.6783 - val_auc: 0.7569\n",
            "Epoch 4/20\n",
            "633/633 [==============================] - 11s 18ms/step - loss: 0.5370 - auc: 0.8059 - val_loss: 0.7495 - val_auc: 0.8184\n",
            "Epoch 5/20\n",
            "633/633 [==============================] - 11s 18ms/step - loss: 0.5195 - auc: 0.8206 - val_loss: 0.8961 - val_auc: 0.8068\n",
            "Epoch 6/20\n",
            "633/633 [==============================] - 11s 17ms/step - loss: 0.4999 - auc: 0.8366 - val_loss: 0.6069 - val_auc: 0.7934\n",
            "Epoch 7/20\n",
            "633/633 [==============================] - 10s 16ms/step - loss: 0.4818 - auc: 0.8499 - val_loss: 0.5890 - val_auc: 0.8024\n",
            "Epoch 8/20\n",
            "633/633 [==============================] - 11s 17ms/step - loss: 0.4591 - auc: 0.8654 - val_loss: 0.6073 - val_auc: 0.8244\n",
            "Epoch 9/20\n",
            "633/633 [==============================] - 11s 17ms/step - loss: 0.4452 - auc: 0.8743 - val_loss: 0.6697 - val_auc: 0.7764\n",
            "Epoch 10/20\n",
            "633/633 [==============================] - 11s 17ms/step - loss: 0.4253 - auc: 0.8863 - val_loss: 0.5627 - val_auc: 0.8453\n",
            "Epoch 11/20\n",
            "633/633 [==============================] - 11s 17ms/step - loss: 0.4112 - auc: 0.8942 - val_loss: 0.6853 - val_auc: 0.8482\n",
            "Epoch 12/20\n",
            "633/633 [==============================] - 11s 17ms/step - loss: 0.4000 - auc: 0.9003 - val_loss: 0.5854 - val_auc: 0.8091\n",
            "Epoch 13/20\n",
            "633/633 [==============================] - 11s 17ms/step - loss: 0.3800 - auc: 0.9102 - val_loss: 0.4339 - val_auc: 0.8463\n",
            "Epoch 14/20\n",
            "633/633 [==============================] - 11s 17ms/step - loss: 0.3678 - auc: 0.9161 - val_loss: 0.4943 - val_auc: 0.8563\n",
            "Epoch 15/20\n",
            "633/633 [==============================] - 11s 17ms/step - loss: 0.3512 - auc: 0.9233 - val_loss: 0.5746 - val_auc: 0.8096\n",
            "Epoch 16/20\n",
            "633/633 [==============================] - 11s 17ms/step - loss: 0.3402 - auc: 0.9279 - val_loss: 0.6191 - val_auc: 0.8465\n",
            "Epoch 17/20\n",
            "633/633 [==============================] - 11s 17ms/step - loss: 0.3296 - auc: 0.9322 - val_loss: 0.5081 - val_auc: 0.7961\n",
            "Epoch 18/20\n",
            "633/633 [==============================] - 11s 17ms/step - loss: 0.3210 - auc: 0.9352 - val_loss: 0.5051 - val_auc: 0.8415\n",
            "Epoch 19/20\n",
            "633/633 [==============================] - 11s 18ms/step - loss: 0.3068 - auc: 0.9406 - val_loss: 0.5761 - val_auc: 0.8589\n",
            "Epoch 20/20\n",
            "633/633 [==============================] - 11s 17ms/step - loss: 0.2936 - auc: 0.9454 - val_loss: 0.5513 - val_auc: 0.8475\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5cd20c8190>"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "uco1TirRKDUR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bBt0vv1KDUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad9ac9d-469c-4a69-a6fa-2a9feb945756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "771/771 [==============================] - 4s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_9 = model_2.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_9 = np.reshape(y_pred_9, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347cce5e-2454-4fa3-90d0-4a5a593d1f8d",
        "id": "GpERbG5oKDUT"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12326"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "len(y_pred_9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yB-2OiwKDUT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_9})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_9.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Trial 10 With Balanced Data**"
      ],
      "metadata": {
        "id": "ASmB9LtlLKDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this trial i used \"message_calculation_class\"] = 'RGCN' as the same in the third trial with the balanced data so the accurracy became 80 and 95 and if i increase in the number of epochs the performance of the model will increase "
      ],
      "metadata": {
        "id": "CVxUPxkJhHgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Model Structure**"
      ],
      "metadata": {
        "id": "RI819obPLKDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing tensorflow and other libraries\n",
        "#GGNN,RGCN,RGAT,RGIN,GNN-Edge-MLP,GNN-FiLM\n",
        "#import tf2_gnn.layers.message_passing.gnn_edge_mlp\n",
        "from  tf2_gnn.layers.message_passing import rgat,rgin,rgcn,gnn_film,ggnn,gnn_edge_mlp\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import segment_mean #to calculate segmented mean\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Input, Model #layers and model\n",
        "from tensorflow.keras.layers import Embedding, Dense #layers\n",
        "from tensorflow.keras.optimizers import Adam #optimizer\n",
        "\n",
        "\n",
        "#Input layer for nodes (tokenized text data)          \n",
        "data = keras.Input(batch_shape=(None,)) \n",
        "# the first dim is different to the previous one. it is the total number of edges in this batch\n",
        "#Input layer for edge data        \n",
        "edge = keras.Input(batch_shape=(None, 2), dtype=tf.int32)   \n",
        "#Input layer for node2graph ids    \n",
        "node2graph = keras.Input(batch_shape=(None,), dtype=tf.int32) \n",
        "#embedding layer over data with each token embedded as  size vector\n",
        "embeded = Embedding(tokenizer.num_words, 50)(data)  \n",
        "\n",
        "# number of graphs (number of samples)\n",
        "#calculating number of samples (or min(batch_size,no._of_samples))  \n",
        "num_graph = tf.reduce_max(node2graph)+1  \n",
        "#gnn_input layer with inputs as defined above\n",
        "gnn_input = GNNInput(\n",
        "    node_features=embeded,\n",
        "    adjacency_lists=(edge,),\n",
        "    node_to_graph_map=node2graph, \n",
        "    num_graphs=num_graph,\n",
        ")\n",
        "\n",
        "# https://github.com/microsoft/tf2-gnn/blob/master/tf2_gnn/layers/gnn.py\n",
        "#defining hyperparameters for GNN layer\n",
        "params = GNN.get_default_hyperparameters()\n",
        "#defining hidden dimension of the gnn layer\n",
        "params[\"hidden_dim\"] = 64\n",
        "#Relational Graph Convolutional Networks  \n",
        "params[\"message_calculation_class\"] = 'RGCN'\n",
        "# params[\"num_edge_MLP_hidden_layers\"] = 32\n",
        "#gnn layer with defined hyperparameters\n",
        "gnn_layer = GNN(params)  \n",
        "\n",
        "#gnn output layer \n",
        "#outpur shape: [data_dimension,hidden layers]  \n",
        "gnn_out = gnn_layer(gnn_input) \n",
        "\n",
        "print('gnn_out', gnn_out)           \n",
        "\n",
        "# https://www.tensorflow.org/api_docs/python/tf/math/segment_mean\n",
        "\n",
        "#calculating segmented mean based on segment_ids\n",
        "avg = segment_mean(\n",
        "    data=gnn_out,\n",
        "    segment_ids=node2graph\n",
        "    )#shape: [batch_size,64] \n",
        "\n",
        "print('mean:', avg)\n",
        "\n",
        "#final dense layer with sigmoid\n",
        "#Output [None,8]\n",
        "fc1 = Dense(8,activation='LeakyReLU')(avg) \n",
        "#output shape: [batch_size,1] \n",
        "pred = Dense(1, activation='sigmoid')(fc1)   \n",
        "print('pred:', pred)\n",
        "\n",
        "#building model \n",
        "#inputs are data,edges and node2graph\n",
        "#input: dictionary\n",
        "#output: prediction value from dense layer\n",
        "model_10 = Model(\n",
        "    inputs={\n",
        "        'data': data, \n",
        "        'edges': edge,\n",
        "        'node2grah': node2graph,\n",
        "    },\n",
        "    outputs=pred\n",
        ")\n",
        "\n",
        "#printing summary of the model\n",
        "model_10.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965d9c4f-d725-43ee-d128-76a459369cf6",
        "id": "4JT0pEOhLKDT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gnn_out KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='gnn_30/StatefulPartitionedCall:0', description=\"created by layer 'gnn_30'\")\n",
            "mean: KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='tf.math.segment_mean_9/SegmentMean:0', description=\"created by layer 'tf.math.segment_mean_9'\")\n",
            "pred: KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_13/Sigmoid:0', description=\"created by layer 'dense_13'\")\n",
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_92 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_90 (InputLayer)          [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_30 (TFOpLam  ()                  0           ['input_92[0][0]']               \n",
            " bda)                                                                                             \n",
            "                                                                                                  \n",
            " embedding_30 (Embedding)       (None, 50)           25000       ['input_90[0][0]']               \n",
            "                                                                                                  \n",
            " input_91 (InputLayer)          [(None, 2)]          0           []                               \n",
            "                                                                                                  \n",
            " tf.__operators__.add_30 (TFOpL  ()                  0           ['tf.math.reduce_max_30[0][0]']  \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " gnn_30 (GNN)                   (None, 64)           73472       ['embedding_30[0][0]',           \n",
            "                                                                  'input_91[0][0]',               \n",
            "                                                                  'input_92[0][0]',               \n",
            "                                                                  'tf.__operators__.add_30[0][0]']\n",
            "                                                                                                  \n",
            " tf.math.segment_mean_9 (TFOpLa  (None, 64)          0           ['gnn_30[0][0]',                 \n",
            " mbda)                                                            'input_92[0][0]']               \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 8)            520         ['tf.math.segment_mean_9[0][0]'] \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 1)            9           ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 99,001\n",
            "Trainable params: 99,001\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Compile The Model**"
      ],
      "metadata": {
        "id": "GvQ0Il0wLKDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_10.compile(optimizer='adam', loss='BinaryCrossentropy', metrics=['AUC'])"
      ],
      "metadata": {
        "id": "wnoXZeLlLKDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Train The Model**"
      ],
      "metadata": {
        "id": "sBJjb2JuLKDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "#math.ceil: returns the smallest integral value greater than the number\n",
        "#no. of batches for training data\n",
        "num_batchs = math.ceil(len(training_set) / batch_size) \n",
        "#no. of batches for validation data\n",
        "num_batchs_validation = math.ceil(len(validation_set) / batch_size) \n",
        "\n",
        "model_10.fit(\n",
        "    gen_batch(\n",
        "        training_set, batch_size=batch_size, repeat=True\n",
        "    ),\n",
        "    steps_per_epoch=num_batchs,\n",
        "    epochs=20,\n",
        "    validation_data=gen_batch(\n",
        "        validation_set, batch_size=16, repeat=True\n",
        "    ),\n",
        "    validation_steps=num_batchs_validation,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd45d339-4c15-4294-a13e-728876b67f0a",
        "id": "ZvlTA8cjLKDW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1265/1265 [==============================] - 26s 17ms/step - loss: 0.6207 - auc: 0.7147 - val_loss: 0.8158 - val_auc: 0.7290\n",
            "Epoch 2/20\n",
            "1265/1265 [==============================] - 17s 13ms/step - loss: 0.5863 - auc: 0.7548 - val_loss: 0.6270 - val_auc: 0.7833\n",
            "Epoch 3/20\n",
            "1265/1265 [==============================] - 18s 15ms/step - loss: 0.5723 - auc: 0.7721 - val_loss: 0.6966 - val_auc: 0.7798\n",
            "Epoch 4/20\n",
            "1265/1265 [==============================] - 16s 13ms/step - loss: 0.5539 - auc: 0.7906 - val_loss: 0.6867 - val_auc: 0.7914\n",
            "Epoch 5/20\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.5325 - auc: 0.8106 - val_loss: 0.4968 - val_auc: 0.8213\n",
            "Epoch 6/20\n",
            "1265/1265 [==============================] - 17s 13ms/step - loss: 0.5090 - auc: 0.8300 - val_loss: 0.7536 - val_auc: 0.8032\n",
            "Epoch 7/20\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.4861 - auc: 0.8466 - val_loss: 0.5048 - val_auc: 0.8111\n",
            "Epoch 8/20\n",
            "1265/1265 [==============================] - 17s 13ms/step - loss: 0.4676 - auc: 0.8597 - val_loss: 0.5581 - val_auc: 0.8161\n",
            "Epoch 9/20\n",
            "1265/1265 [==============================] - 17s 13ms/step - loss: 0.4528 - auc: 0.8702 - val_loss: 0.5308 - val_auc: 0.7900\n",
            "Epoch 10/20\n",
            "1265/1265 [==============================] - 17s 13ms/step - loss: 0.4361 - auc: 0.8807 - val_loss: 0.5801 - val_auc: 0.7921\n",
            "Epoch 11/20\n",
            "1265/1265 [==============================] - 17s 13ms/step - loss: 0.4186 - auc: 0.8908 - val_loss: 0.7049 - val_auc: 0.7722\n",
            "Epoch 12/20\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.4018 - auc: 0.8997 - val_loss: 0.6058 - val_auc: 0.8302\n",
            "Epoch 13/20\n",
            "1265/1265 [==============================] - 16s 13ms/step - loss: 0.3919 - auc: 0.9050 - val_loss: 0.5948 - val_auc: 0.8474\n",
            "Epoch 14/20\n",
            "1265/1265 [==============================] - 16s 13ms/step - loss: 0.3863 - auc: 0.9082 - val_loss: 0.8062 - val_auc: 0.7480\n",
            "Epoch 15/20\n",
            "1265/1265 [==============================] - 17s 13ms/step - loss: 0.3627 - auc: 0.9190 - val_loss: 0.4810 - val_auc: 0.8241\n",
            "Epoch 16/20\n",
            "1265/1265 [==============================] - 16s 13ms/step - loss: 0.3488 - auc: 0.9252 - val_loss: 0.4746 - val_auc: 0.7871\n",
            "Epoch 17/20\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.3358 - auc: 0.9314 - val_loss: 0.5378 - val_auc: 0.8083\n",
            "Epoch 18/20\n",
            "1265/1265 [==============================] - 16s 13ms/step - loss: 0.3260 - auc: 0.9350 - val_loss: 0.4786 - val_auc: 0.8324\n",
            "Epoch 19/20\n",
            "1265/1265 [==============================] - 16s 13ms/step - loss: 0.3183 - auc: 0.9382 - val_loss: 0.5058 - val_auc: 0.8553\n",
            "Epoch 20/20\n",
            "1265/1265 [==============================] - 17s 14ms/step - loss: 0.3081 - auc: 0.9420 - val_loss: 0.6130 - val_auc: 0.8009\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5c70201850>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Predictoin And Submission**"
      ],
      "metadata": {
        "id": "dxOBwnORLKDX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoxKSoCZLKDX"
      },
      "outputs": [],
      "source": [
        "#make prediction on test data by using the trained model \n",
        "y_pred_10 = model_10.predict(\n",
        "    gen_batch(testing_set, batch_size=16, shuffle=False)\n",
        ")\n",
        "y_pred_10 = np.reshape(y_pred_10, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuyFY-nLLKDX"
      },
      "outputs": [],
      "source": [
        "len(y_pred_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZdL9i5ZLKDY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "submission = pd.DataFrame({'label':y_pred_10})\n",
        "submission.index.name = 'id'\n",
        "submission.to_csv('submission_model_10.csv')"
      ]
    }
  ]
}